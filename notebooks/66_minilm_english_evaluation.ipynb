{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 66. all-MiniLM-L6-v2 英語限定評価\n",
    "\n",
    "## 目的\n",
    "- all-MiniLM-L6-v2 (FastEmbed ONNX) と E5-base の性能比較\n",
    "- 英語データでの検索品質（Recall@10）評価\n",
    "- CPU速度比較\n",
    "- all-MiniLM-L6-v2 用のITQ LSH・Pivot学習データ作成\n",
    "\n",
    "## 比較対象\n",
    "| モデル | ライブラリ | 次元数 | 特徴 |\n",
    "|--------|------------|--------|------|\n",
    "| all-MiniLM-L6-v2 | FastEmbed (ONNX) | 384 | 高速、英語専用 |\n",
    "| multilingual-e5-base | sentence-transformers | 768 | 高品質、多言語対応 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:18:33.205313Z",
     "iopub.status.busy": "2026-02-04T07:18:33.205126Z",
     "iopub.status.idle": "2026-02-04T07:18:33.271251Z",
     "shell.execute_reply": "2026-02-04T07:18:33.270736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 10000\n",
      "ITQ bits: 128\n",
      "Pivots: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.itq_lsh import ITQLSH, hamming_distance_batch\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# 設定\n",
    "N_DOCUMENTS = 10000\n",
    "N_BITS = 128\n",
    "N_PIVOTS = 8\n",
    "\n",
    "print(f\"Documents: {N_DOCUMENTS}\")\n",
    "print(f\"ITQ bits: {N_BITS}\")\n",
    "print(f\"Pivots: {N_PIVOTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 英語データ準備（Wikipedia English）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:18:33.305538Z",
     "iopub.status.busy": "2026-02-04T07:18:33.305294Z",
     "iopub.status.idle": "2026-02-04T07:18:46.101883Z",
     "shell.execute_reply": "2026-02-04T07:18:46.101225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Wikipedia English dataset (streaming)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf02b09b2cf49b7bc07fff7c1a8b142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 10000 documents\n",
      "Sample: Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typi...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading Wikipedia English dataset (streaming)...\")\n",
    "wiki_en = load_dataset(\n",
    "    \"wikimedia/wikipedia\",\n",
    "    \"20231101.en\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# 10,000件のドキュメントを収集\n",
    "documents = []\n",
    "for i, item in enumerate(wiki_en):\n",
    "    if len(documents) >= N_DOCUMENTS:\n",
    "        break\n",
    "    text = item['text'][:500].strip()\n",
    "    if len(text) >= 50:  # 短すぎるものは除外\n",
    "        documents.append(text)\n",
    "\n",
    "print(f\"Collected {len(documents)} documents\")\n",
    "print(f\"Sample: {documents[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. モデルのロードと埋め込み生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:18:46.103421Z",
     "iopub.status.busy": "2026-02-04T07:18:46.103161Z",
     "iopub.status.idle": "2026-02-04T07:20:28.001855Z",
     "shell.execute_reply": "2026-02-04T07:20:28.001227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all-MiniLM-L6-v2 (FastEmbed)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2026-02-04 16:18:46.138738459 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card0/device/vendor\"\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded in 0.2s\n",
      "\n",
      "Generating embeddings with all-MiniLM-L6-v2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (10000, 384)\n",
      "  Time: 101.7s (10.2 ms/doc)\n"
     ]
    }
   ],
   "source": [
    "# FastEmbed: all-MiniLM-L6-v2\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "print(\"Loading all-MiniLM-L6-v2 (FastEmbed)...\")\n",
    "start = time.time()\n",
    "minilm_model = TextEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "minilm_load_time = time.time() - start\n",
    "print(f\"  Loaded in {minilm_load_time:.1f}s\")\n",
    "\n",
    "# 埋め込み生成\n",
    "print(\"\\nGenerating embeddings with all-MiniLM-L6-v2...\")\n",
    "start = time.time()\n",
    "minilm_embeddings = np.array(list(minilm_model.embed(documents)))\n",
    "minilm_embed_time = time.time() - start\n",
    "print(f\"  Shape: {minilm_embeddings.shape}\")\n",
    "print(f\"  Time: {minilm_embed_time:.1f}s ({minilm_embed_time/len(documents)*1000:.1f} ms/doc)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:20:28.003319Z",
     "iopub.status.busy": "2026-02-04T07:20:28.003159Z",
     "iopub.status.idle": "2026-02-04T07:30:58.243048Z",
     "shell.execute_reply": "2026-02-04T07:30:58.242427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading multilingual-e5-base (sentence-transformers)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded in 4.2s\n",
      "\n",
      "Generating embeddings with E5-base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac4d9f8e96e4ef3a5fdfa41c03b7221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (10000, 768)\n",
      "  Time: 624.1s (62.4 ms/doc)\n"
     ]
    }
   ],
   "source": [
    "# Sentence-Transformers: E5-base\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Loading multilingual-e5-base (sentence-transformers)...\")\n",
    "start = time.time()\n",
    "e5_model = SentenceTransformer(\"intfloat/multilingual-e5-base\", device=\"cpu\")\n",
    "e5_load_time = time.time() - start\n",
    "print(f\"  Loaded in {e5_load_time:.1f}s\")\n",
    "\n",
    "# 埋め込み生成（E5はpassage:プレフィックス必要）\n",
    "print(\"\\nGenerating embeddings with E5-base...\")\n",
    "docs_with_prefix = [f\"passage: {d}\" for d in documents]\n",
    "start = time.time()\n",
    "e5_embeddings = e5_model.encode(docs_with_prefix, show_progress_bar=True, convert_to_numpy=True)\n",
    "e5_embed_time = time.time() - start\n",
    "print(f\"  Shape: {e5_embeddings.shape}\")\n",
    "print(f\"  Time: {e5_embed_time:.1f}s ({e5_embed_time/len(documents)*1000:.1f} ms/doc)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:30:58.244531Z",
     "iopub.status.busy": "2026-02-04T07:30:58.244243Z",
     "iopub.status.idle": "2026-02-04T07:30:58.247597Z",
     "shell.execute_reply": "2026-02-04T07:30:58.247126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CPU Speed Comparison (10,000 documents)\n",
      "============================================================\n",
      "Model                             Dim   Time (s)     ms/doc    Speedup\n",
      "----------------------------------------------------------------------\n",
      "all-MiniLM-L6-v2 (FastEmbed)      384      101.7       10.2       6.1x\n",
      "multilingual-e5-base (ST)         768      624.1       62.4        1.0x\n"
     ]
    }
   ],
   "source": [
    "# 速度比較サマリー\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CPU Speed Comparison (10,000 documents)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<30} {'Dim':>6} {'Time (s)':>10} {'ms/doc':>10} {'Speedup':>10}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'all-MiniLM-L6-v2 (FastEmbed)':<30} {384:>6} {minilm_embed_time:>10.1f} {minilm_embed_time/len(documents)*1000:>10.1f} {e5_embed_time/minilm_embed_time:>9.1f}x\")\n",
    "print(f\"{'multilingual-e5-base (ST)':<30} {768:>6} {e5_embed_time:>10.1f} {e5_embed_time/len(documents)*1000:>10.1f} {'1.0':>10}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 検索品質比較（Recall@10）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:30:58.248816Z",
     "iopub.status.busy": "2026-02-04T07:30:58.248691Z",
     "iopub.status.idle": "2026-02-04T07:31:03.125696Z",
     "shell.execute_reply": "2026-02-04T07:31:03.124803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cross-model similarity...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 Overlap between MiniLM and E5: 37.9% ± 21.9%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_recall_at_k(query_embeddings, doc_embeddings, k=10, n_queries=100):\n",
    "    \"\"\"\n",
    "    ランダムなクエリでRecall@kを計算\n",
    "    Ground truth: 同じモデルでのコサイン類似度Top-k\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    query_indices = np.random.choice(len(doc_embeddings), n_queries, replace=False)\n",
    "    \n",
    "    recalls = []\n",
    "    for idx in query_indices:\n",
    "        query = doc_embeddings[idx:idx+1]\n",
    "        \n",
    "        # コサイン類似度で検索\n",
    "        similarities = cosine_similarity(query, doc_embeddings)[0]\n",
    "        similarities[idx] = -1  # 自分自身を除外\n",
    "        \n",
    "        top_k = np.argsort(similarities)[-k:][::-1]\n",
    "        recalls.append(1.0)  # 同じモデルなので常に100%\n",
    "    \n",
    "    return np.mean(recalls)\n",
    "\n",
    "# クロスモデル比較: MiniLMのクエリでE5の結果と比較\n",
    "def cross_model_similarity(minilm_emb, e5_emb, n_queries=100, k=10):\n",
    "    \"\"\"\n",
    "    MiniLMとE5で同じドキュメントの検索結果がどれだけ一致するか\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    query_indices = np.random.choice(len(minilm_emb), n_queries, replace=False)\n",
    "    \n",
    "    overlaps = []\n",
    "    for idx in query_indices:\n",
    "        # MiniLMでの検索結果\n",
    "        minilm_sim = cosine_similarity(minilm_emb[idx:idx+1], minilm_emb)[0]\n",
    "        minilm_sim[idx] = -1\n",
    "        minilm_top_k = set(np.argsort(minilm_sim)[-k:])\n",
    "        \n",
    "        # E5での検索結果\n",
    "        e5_sim = cosine_similarity(e5_emb[idx:idx+1], e5_emb)[0]\n",
    "        e5_sim[idx] = -1\n",
    "        e5_top_k = set(np.argsort(e5_sim)[-k:])\n",
    "        \n",
    "        # 重複率\n",
    "        overlap = len(minilm_top_k & e5_top_k) / k\n",
    "        overlaps.append(overlap)\n",
    "    \n",
    "    return np.mean(overlaps), np.std(overlaps)\n",
    "\n",
    "print(\"Computing cross-model similarity...\")\n",
    "overlap_mean, overlap_std = cross_model_similarity(minilm_embeddings, e5_embeddings, n_queries=200, k=10)\n",
    "print(f\"\\nTop-10 Overlap between MiniLM and E5: {overlap_mean*100:.1f}% ± {overlap_std*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:31:03.127478Z",
     "iopub.status.busy": "2026-02-04T07:31:03.127098Z",
     "iopub.status.idle": "2026-02-04T07:31:27.730118Z",
     "shell.execute_reply": "2026-02-04T07:31:27.729241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-K Overlap Analysis:\n",
      "    K      Overlap        Std\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5        37.0%      24.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10        37.9%      21.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20        39.2%      19.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50        38.9%      14.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100        39.6%      13.5%\n"
     ]
    }
   ],
   "source": [
    "# 複数のkで比較\n",
    "print(\"\\nTop-K Overlap Analysis:\")\n",
    "print(f\"{'K':>5} {'Overlap':>12} {'Std':>10}\")\n",
    "print(\"-\"*30)\n",
    "for k in [5, 10, 20, 50, 100]:\n",
    "    overlap_mean, overlap_std = cross_model_similarity(minilm_embeddings, e5_embeddings, n_queries=200, k=k)\n",
    "    print(f\"{k:>5} {overlap_mean*100:>11.1f}% {overlap_std*100:>9.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. all-MiniLM-L6-v2 用 ITQ学習と保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:31:27.732535Z",
     "iopub.status.busy": "2026-02-04T07:31:27.732290Z",
     "iopub.status.idle": "2026-02-04T07:31:28.341488Z",
     "shell.execute_reply": "2026-02-04T07:31:28.340446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ITQ with 128 bits...\n",
      "ITQ学習開始: samples=10000, dim=384, bits=128\n",
      "  Centering完了: mean_norm=0.1440\n",
      "  PCA完了: explained_variance=79.61%\n",
      "  ITQ iteration 10: quantization_error=0.8786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ITQ iteration 20: quantization_error=0.8779\n",
      "  ITQ iteration 30: quantization_error=0.8775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ITQ iteration 40: quantization_error=0.8774\n",
      "  ITQ iteration 50: quantization_error=0.8773\n",
      "ITQ学習完了\n",
      "Hash shape: (10000, 128)\n",
      "Saved: itq_minilm_128bits.pkl, 10k_minilm_hashes_128bits.npy\n"
     ]
    }
   ],
   "source": [
    "# ITQ学習\n",
    "print(f\"Training ITQ with {N_BITS} bits...\")\n",
    "itq = ITQLSH(n_bits=N_BITS, n_iterations=50)\n",
    "itq.fit(minilm_embeddings)\n",
    "\n",
    "# ハッシュ生成\n",
    "minilm_hashes = itq.transform(minilm_embeddings)\n",
    "print(f\"Hash shape: {minilm_hashes.shape}\")\n",
    "\n",
    "# 保存\n",
    "itq.save(DATA_DIR / \"itq_minilm_128bits.pkl\")\n",
    "np.save(DATA_DIR / \"10k_minilm_hashes_128bits.npy\", minilm_hashes)\n",
    "print(f\"Saved: itq_minilm_128bits.pkl, 10k_minilm_hashes_128bits.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:31:28.343178Z",
     "iopub.status.busy": "2026-02-04T07:31:28.343011Z",
     "iopub.status.idle": "2026-02-04T07:31:28.392840Z",
     "shell.execute_reply": "2026-02-04T07:31:28.391747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spearman correlation (cosine vs hamming): -0.0225\n",
      "(Negative correlation expected: lower hamming = higher similarity)\n"
     ]
    }
   ],
   "source": [
    "# ITQ品質評価：ハミング距離とコサイン類似度の相関\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(minilm_embeddings), 500, replace=False)\n",
    "sample_emb = minilm_embeddings[sample_indices]\n",
    "sample_hashes = minilm_hashes[sample_indices]\n",
    "\n",
    "# コサイン類似度行列\n",
    "cos_sim_matrix = cosine_similarity(sample_emb)\n",
    "\n",
    "# ハミング距離行列\n",
    "hamming_matrix = np.zeros((len(sample_hashes), len(sample_hashes)))\n",
    "for i in range(len(sample_hashes)):\n",
    "    hamming_matrix[i] = hamming_distance_batch(sample_hashes[i:i+1], sample_hashes)[0]\n",
    "\n",
    "# 上三角部分のみ取得（対角除く）\n",
    "upper_indices = np.triu_indices(len(sample_hashes), k=1)\n",
    "cos_values = cos_sim_matrix[upper_indices]\n",
    "hamming_values = hamming_matrix[upper_indices]\n",
    "\n",
    "# 相関係数\n",
    "correlation, p_value = spearmanr(cos_values, hamming_values)\n",
    "print(f\"\\nSpearman correlation (cosine vs hamming): {correlation:.4f}\")\n",
    "print(f\"(Negative correlation expected: lower hamming = higher similarity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pivot選択と保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:31:28.394991Z",
     "iopub.status.busy": "2026-02-04T07:31:28.394330Z",
     "iopub.status.idle": "2026-02-04T07:31:28.524931Z",
     "shell.execute_reply": "2026-02-04T07:31:28.524236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 8 pivots using Furthest First...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot indices: [7270 3722 2751 7590 4513 4020 5414 7975]\n",
      "Pivot distances shape: (10000, 8)\n",
      "Saved: pivots_8_minilm.npy, 10k_minilm_pivot_distances.npy, 10k_minilm_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "def select_pivots_furthest_first(embeddings, n_pivots):\n",
    "    \"\"\"\n",
    "    Furthest First法でピボットを選択\n",
    "    \"\"\"\n",
    "    n = len(embeddings)\n",
    "    pivot_indices = []\n",
    "    \n",
    "    # 最初のピボットはランダム\n",
    "    np.random.seed(42)\n",
    "    first_pivot = np.random.randint(n)\n",
    "    pivot_indices.append(first_pivot)\n",
    "    \n",
    "    # 各点から最も近いピボットまでの距離\n",
    "    min_distances = np.full(n, np.inf)\n",
    "    \n",
    "    for _ in range(n_pivots - 1):\n",
    "        # 最新ピボットからの距離を計算\n",
    "        last_pivot = pivot_indices[-1]\n",
    "        distances = 1 - cosine_similarity(embeddings, embeddings[last_pivot:last_pivot+1]).flatten()\n",
    "        \n",
    "        # 最小距離を更新\n",
    "        min_distances = np.minimum(min_distances, distances)\n",
    "        \n",
    "        # 既存ピボットを除外\n",
    "        min_distances[pivot_indices] = -1\n",
    "        \n",
    "        # 最も遠い点を次のピボットに\n",
    "        next_pivot = np.argmax(min_distances)\n",
    "        pivot_indices.append(next_pivot)\n",
    "    \n",
    "    return np.array(pivot_indices)\n",
    "\n",
    "# ピボット選択\n",
    "print(f\"Selecting {N_PIVOTS} pivots using Furthest First...\")\n",
    "pivot_indices = select_pivots_furthest_first(minilm_embeddings, N_PIVOTS)\n",
    "pivots = minilm_embeddings[pivot_indices]\n",
    "print(f\"Pivot indices: {pivot_indices}\")\n",
    "\n",
    "# 全ドキュメントとピボット間の距離\n",
    "pivot_distances = 1 - cosine_similarity(minilm_embeddings, pivots)\n",
    "print(f\"Pivot distances shape: {pivot_distances.shape}\")\n",
    "\n",
    "# 保存\n",
    "np.save(DATA_DIR / \"pivots_8_minilm.npy\", pivots)\n",
    "np.save(DATA_DIR / \"10k_minilm_pivot_distances.npy\", pivot_distances)\n",
    "np.save(DATA_DIR / \"10k_minilm_embeddings.npy\", minilm_embeddings)\n",
    "print(f\"Saved: pivots_8_minilm.npy, 10k_minilm_pivot_distances.npy, 10k_minilm_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ITQ LSH + Pivot 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:31:28.527398Z",
     "iopub.status.busy": "2026-02-04T07:31:28.527213Z",
     "iopub.status.idle": "2026-02-04T07:31:30.277818Z",
     "shell.execute_reply": "2026-02-04T07:31:30.276762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ITQ LSH...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ITQ LSH Recall@10:\n",
      "  Candidates    Recall@10\n",
      "--------------------------\n",
      "         100        82.6%\n",
      "         500        96.9%\n",
      "        1000        98.9%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_itq_lsh(query_idx, embeddings, hashes, k=10, candidates_list=[100, 500, 1000]):\n",
    "    \"\"\"\n",
    "    ITQ LSHでの検索評価\n",
    "    \"\"\"\n",
    "    query_emb = embeddings[query_idx:query_idx+1]\n",
    "    query_hash = hashes[query_idx:query_idx+1]\n",
    "    \n",
    "    # Ground truth: コサイン類似度Top-k\n",
    "    cos_sim = cosine_similarity(query_emb, embeddings)[0]\n",
    "    cos_sim[query_idx] = -1\n",
    "    ground_truth = set(np.argsort(cos_sim)[-k:])\n",
    "    \n",
    "    results = {}\n",
    "    for n_candidates in candidates_list:\n",
    "        # ハミング距離で候補取得\n",
    "        hamming_dists = hamming_distance_batch(query_hash, hashes)\n",
    "        hamming_dists = hamming_dists.astype(float)  # int -> float for inf assignment\n",
    "        hamming_dists[query_idx] = np.inf\n",
    "        candidates = np.argsort(hamming_dists)[:n_candidates]\n",
    "        \n",
    "        # 候補内でコサイン類似度再ランク\n",
    "        candidate_sims = cosine_similarity(query_emb, embeddings[candidates])[0]\n",
    "        top_k_in_candidates = candidates[np.argsort(candidate_sims)[-k:]]\n",
    "        \n",
    "        recall = len(set(top_k_in_candidates) & ground_truth) / k\n",
    "        results[n_candidates] = recall\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_pivot_filter(query_idx, embeddings, pivot_distances, threshold, k=10):\n",
    "    \"\"\"\n",
    "    Pivotフィルタリングの評価\n",
    "    \"\"\"\n",
    "    query_emb = embeddings[query_idx:query_idx+1]\n",
    "    query_pivot_dist = pivot_distances[query_idx]\n",
    "    \n",
    "    # Ground truth\n",
    "    cos_sim = cosine_similarity(query_emb, embeddings)[0]\n",
    "    cos_sim[query_idx] = -1\n",
    "    ground_truth = set(np.argsort(cos_sim)[-k:])\n",
    "    \n",
    "    # Pivotフィルタ: |d(q,p) - d(x,p)| < threshold for all pivots\n",
    "    dist_diff = np.abs(pivot_distances - query_pivot_dist)\n",
    "    max_diff = np.max(dist_diff, axis=1)\n",
    "    candidates_mask = max_diff < threshold\n",
    "    candidates_mask[query_idx] = False\n",
    "    \n",
    "    n_candidates = np.sum(candidates_mask)\n",
    "    reduction_rate = 1 - n_candidates / (len(embeddings) - 1)\n",
    "    \n",
    "    # フィルタ後の候補でRecall計算\n",
    "    if n_candidates > 0:\n",
    "        candidate_indices = np.where(candidates_mask)[0]\n",
    "        filter_recall = len(set(candidate_indices) & ground_truth) / k\n",
    "    else:\n",
    "        filter_recall = 0.0\n",
    "    \n",
    "    return filter_recall, reduction_rate, n_candidates\n",
    "\n",
    "# 評価実行\n",
    "np.random.seed(42)\n",
    "test_queries = np.random.choice(len(minilm_embeddings), 100, replace=False)\n",
    "\n",
    "print(\"Evaluating ITQ LSH...\")\n",
    "itq_results = {100: [], 500: [], 1000: []}\n",
    "for idx in test_queries:\n",
    "    results = evaluate_itq_lsh(idx, minilm_embeddings, minilm_hashes)\n",
    "    for n_cand, recall in results.items():\n",
    "        itq_results[n_cand].append(recall)\n",
    "\n",
    "print(\"\\nITQ LSH Recall@10:\")\n",
    "print(f\"{'Candidates':>12} {'Recall@10':>12}\")\n",
    "print(\"-\"*26)\n",
    "for n_cand in [100, 500, 1000]:\n",
    "    mean_recall = np.mean(itq_results[n_cand])\n",
    "    print(f\"{n_cand:>12} {mean_recall*100:>11.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:31:30.279677Z",
     "iopub.status.busy": "2026-02-04T07:31:30.279498Z",
     "iopub.status.idle": "2026-02-04T07:31:36.485016Z",
     "shell.execute_reply": "2026-02-04T07:31:36.483962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Pivot Filter...\n",
      "\n",
      " Threshold  Filter Recall    Reduction   Avg Candidates\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.10          22.4%        96.9%              310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.15          64.7%        79.6%             2041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.20          89.8%        52.3%             4774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.25          96.7%        29.2%             7077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.30          99.0%        14.6%             8539\n"
     ]
    }
   ],
   "source": [
    "# Pivotフィルタ評価\n",
    "print(\"\\nEvaluating Pivot Filter...\")\n",
    "thresholds = [0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "\n",
    "print(f\"\\n{'Threshold':>10} {'Filter Recall':>14} {'Reduction':>12} {'Avg Candidates':>16}\")\n",
    "print(\"-\"*55)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    filter_recalls = []\n",
    "    reduction_rates = []\n",
    "    n_candidates_list = []\n",
    "    \n",
    "    for idx in test_queries:\n",
    "        fr, rr, nc = evaluate_pivot_filter(idx, minilm_embeddings, pivot_distances, threshold)\n",
    "        filter_recalls.append(fr)\n",
    "        reduction_rates.append(rr)\n",
    "        n_candidates_list.append(nc)\n",
    "    \n",
    "    mean_fr = np.mean(filter_recalls)\n",
    "    mean_rr = np.mean(reduction_rates)\n",
    "    mean_nc = np.mean(n_candidates_list)\n",
    "    print(f\"{threshold:>10.2f} {mean_fr*100:>13.1f}% {mean_rr*100:>11.1f}% {mean_nc:>16.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. E5-base との比較（同じ評価）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:31:36.486951Z",
     "iopub.status.busy": "2026-02-04T07:31:36.486774Z",
     "iopub.status.idle": "2026-02-04T07:31:39.241798Z",
     "shell.execute_reply": "2026-02-04T07:31:39.241228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ITQ for E5-base...\n",
      "ITQ学習開始: samples=10000, dim=768, bits=128\n",
      "  Centering完了: mean_norm=0.8404\n",
      "  PCA完了: explained_variance=61.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ITQ iteration 10: quantization_error=0.9399\n",
      "  ITQ iteration 20: quantization_error=0.9396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ITQ iteration 30: quantization_error=0.9394\n",
      "  ITQ iteration 40: quantization_error=0.9393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ITQ iteration 50: quantization_error=0.9392\n",
      "ITQ学習完了\n",
      "Selecting pivots for E5-base...\n",
      "\n",
      "Evaluating ITQ LSH for E5-base...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ITQ LSH Recall@10 (E5-base):\n",
      "  Candidates=100: 82.3%\n",
      "  Candidates=500: 96.7%\n",
      "  Candidates=1000: 98.8%\n"
     ]
    }
   ],
   "source": [
    "# E5-base用のITQ学習\n",
    "print(\"Training ITQ for E5-base...\")\n",
    "itq_e5 = ITQLSH(n_bits=N_BITS, n_iterations=50)\n",
    "itq_e5.fit(e5_embeddings)\n",
    "e5_hashes = itq_e5.transform(e5_embeddings)\n",
    "\n",
    "# E5-base用のPivot\n",
    "print(\"Selecting pivots for E5-base...\")\n",
    "e5_pivot_indices = select_pivots_furthest_first(e5_embeddings, N_PIVOTS)\n",
    "e5_pivots = e5_embeddings[e5_pivot_indices]\n",
    "e5_pivot_distances = 1 - cosine_similarity(e5_embeddings, e5_pivots)\n",
    "\n",
    "# ITQ評価\n",
    "print(\"\\nEvaluating ITQ LSH for E5-base...\")\n",
    "e5_itq_results = {100: [], 500: [], 1000: []}\n",
    "for idx in test_queries:\n",
    "    results = evaluate_itq_lsh(idx, e5_embeddings, e5_hashes)\n",
    "    for n_cand, recall in results.items():\n",
    "        e5_itq_results[n_cand].append(recall)\n",
    "\n",
    "print(\"\\nITQ LSH Recall@10 (E5-base):\")\n",
    "for n_cand in [100, 500, 1000]:\n",
    "    mean_recall = np.mean(e5_itq_results[n_cand])\n",
    "    print(f\"  Candidates={n_cand}: {mean_recall*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:31:39.244015Z",
     "iopub.status.busy": "2026-02-04T07:31:39.243865Z",
     "iopub.status.idle": "2026-02-04T07:31:43.662937Z",
     "shell.execute_reply": "2026-02-04T07:31:43.662239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivot Filter Evaluation (E5-base):\n",
      " Threshold  Filter Recall    Reduction\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.15         100.0%         0.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.20         100.0%         0.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.25         100.0%         0.1%\n"
     ]
    }
   ],
   "source": [
    "# Pivotフィルタ評価（E5-base）\n",
    "print(\"\\nPivot Filter Evaluation (E5-base):\")\n",
    "print(f\"{'Threshold':>10} {'Filter Recall':>14} {'Reduction':>12}\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for threshold in [0.15, 0.20, 0.25]:\n",
    "    filter_recalls = []\n",
    "    reduction_rates = []\n",
    "    \n",
    "    for idx in test_queries:\n",
    "        fr, rr, nc = evaluate_pivot_filter(idx, e5_embeddings, e5_pivot_distances, threshold)\n",
    "        filter_recalls.append(fr)\n",
    "        reduction_rates.append(rr)\n",
    "    \n",
    "    print(f\"{threshold:>10.2f} {np.mean(filter_recalls)*100:>13.1f}% {np.mean(reduction_rates)*100:>11.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 総合比較サマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:31:43.664555Z",
     "iopub.status.busy": "2026-02-04T07:31:43.664375Z",
     "iopub.status.idle": "2026-02-04T07:31:48.571948Z",
     "shell.execute_reply": "2026-02-04T07:31:48.570926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Final Comparison: all-MiniLM-L6-v2 vs E5-base\n",
      "======================================================================\n",
      "\n",
      "【CPU Performance (10,000 English documents)】\n",
      "  all-MiniLM-L6-v2 (FastEmbed): 101.7s (10.2 ms/doc)\n",
      "  E5-base (sentence-transformers): 624.1s (62.4 ms/doc)\n",
      "  Speedup: 6.1x\n",
      "\n",
      "【Search Quality (Top-10 Overlap)】\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MiniLM vs E5 Top-10 overlap: 37.9%\n",
      "\n",
      "【ITQ LSH Recall@10 (candidates=500)】\n",
      "  all-MiniLM-L6-v2: 96.9%\n",
      "  E5-base: 96.7%\n",
      "\n",
      "【Saved Files for all-MiniLM-L6-v2】\n",
      "  - itq_minilm_128bits.pkl\n",
      "  - 10k_minilm_hashes_128bits.npy\n",
      "  - pivots_8_minilm.npy\n",
      "  - 10k_minilm_pivot_distances.npy\n",
      "  - 10k_minilm_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Final Comparison: all-MiniLM-L6-v2 vs E5-base\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n【CPU Performance (10,000 English documents)】\")\n",
    "print(f\"  all-MiniLM-L6-v2 (FastEmbed): {minilm_embed_time:.1f}s ({minilm_embed_time/len(documents)*1000:.1f} ms/doc)\")\n",
    "print(f\"  E5-base (sentence-transformers): {e5_embed_time:.1f}s ({e5_embed_time/len(documents)*1000:.1f} ms/doc)\")\n",
    "print(f\"  Speedup: {e5_embed_time/minilm_embed_time:.1f}x\")\n",
    "\n",
    "print(\"\\n【Search Quality (Top-10 Overlap)】\")\n",
    "overlap_mean, _ = cross_model_similarity(minilm_embeddings, e5_embeddings, n_queries=200, k=10)\n",
    "print(f\"  MiniLM vs E5 Top-10 overlap: {overlap_mean*100:.1f}%\")\n",
    "\n",
    "print(\"\\n【ITQ LSH Recall@10 (candidates=500)】\")\n",
    "print(f\"  all-MiniLM-L6-v2: {np.mean(itq_results[500])*100:.1f}%\")\n",
    "print(f\"  E5-base: {np.mean(e5_itq_results[500])*100:.1f}%\")\n",
    "\n",
    "print(\"\\n【Saved Files for all-MiniLM-L6-v2】\")\n",
    "print(f\"  - itq_minilm_128bits.pkl\")\n",
    "print(f\"  - 10k_minilm_hashes_128bits.npy\")\n",
    "print(f\"  - pivots_8_minilm.npy\")\n",
    "print(f\"  - 10k_minilm_pivot_distances.npy\")\n",
    "print(f\"  - 10k_minilm_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# 実験66 結果サマリー\n\n## CPU性能比較（10,000件英語Wikipedia）\n\n| モデル | 次元 | 処理時間 | ms/doc | Speedup |\n|--------|------|----------|--------|---------|\n| **all-MiniLM-L6-v2 (FastEmbed)** | 384 | 101.7s | **10.2** | **6.1x** |\n| multilingual-e5-base (ST) | 768 | 624.1s | 62.4 | 1.0x |\n\n## 検索品質比較\n\n### Top-K オーバーラップ（MiniLM vs E5-base）\n| K | オーバーラップ |\n|---|---------------|\n| 5 | 37.0% |\n| 10 | 37.9% |\n| 20 | 39.2% |\n| 100 | 39.6% |\n\n**重要な発見**: 両モデルの検索結果は**約38%しか一致しない**。これはモデル間で意味理解が大きく異なることを示す。\n\n## ITQ LSH 評価\n\n### Recall@10\n| 候補数 | MiniLM | E5-base |\n|--------|--------|---------|\n| 100 | 82.6% | 82.3% |\n| 500 | 96.9% | 96.7% |\n| 1000 | 98.9% | 98.8% |\n\n両モデルとも同等のITQ LSH性能を発揮。\n\n### ハミング距離相関\n| モデル | Spearman相関 |\n|--------|-------------|\n| MiniLM | **-0.0225** (非常に弱い) |\n| E5-base (参考: 実験61-63より) | -0.65〜-0.75 |\n\n**注意**: MiniLMのITQハッシュはコサイン類似度との相関が非常に弱い。PCA説明分散は79.6%と高いが、ベクトル空間の特性がITQに適していない可能性がある。\n\n## Pivot フィルタリング\n\n### MiniLM\n| Threshold | Filter Recall | Reduction | 候補数 |\n|-----------|--------------|-----------|--------|\n| 0.15 | 64.7% | 79.6% | 2,041 |\n| 0.20 | 89.8% | 52.3% | 4,774 |\n| 0.25 | 96.7% | 29.2% | 7,077 |\n\n### E5-base\n| Threshold | Filter Recall | Reduction |\n|-----------|--------------|-----------|\n| 0.15 | 100.0% | 0.4% |\n| 0.20 | 100.0% | 0.2% |\n| 0.25 | 100.0% | 0.1% |\n\n**重要**: E5-baseのPivotフィルタは英語データでほぼ機能しない（削減率が非常に低い）。これはE5-baseの異方性が強く、ベクトルが狭い範囲に集中しているため。\n\n## 保存ファイル（all-MiniLM-L6-v2用）\n- `itq_minilm_128bits.pkl` - ITQモデル\n- `10k_minilm_hashes_128bits.npy` - ハッシュ\n- `pivots_8_minilm.npy` - 8ピボット\n- `10k_minilm_pivot_distances.npy` - ピボット距離\n- `10k_minilm_embeddings.npy` - 埋め込み\n\n## 結論\n\n### MiniLMのメリット\n- **6.1倍高速**なCPU推論\n- Pivotフィルタが効果的に機能（threshold=0.20で52%削減、90%recall維持）\n\n### MiniLMの課題\n- E5-baseとの検索結果一致率が低い（約38%）→ 品質差がある可能性\n- ITQハミング距離とコサイン類似度の相関が非常に弱い\n\n### 推奨\n| ユースケース | 推奨モデル |\n|--------------|------------|\n| **英語のみ + 速度最優先** | all-MiniLM-L6-v2 |\n| **英語のみ + 品質重視** | E5-base（または他の大型モデル） |\n| **日本語含む** | multilingual-e5-small/base |",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01a547928418426fac574f40e413bac1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "05b7cdf673094a07b39748565af0dbd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "05d96b601f064a968b95f33035d6d337": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "083e18f034c4471a895dc999f4d49f7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0dcf25c6cd08446b9a120eed74dc93fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "14e8a09c7c20442f9703eeb164b4a1a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_99f9b52646ab4862ac2acd8c5a6d3f3d",
       "placeholder": "​",
       "style": "IPY_MODEL_f248f9e1ca664aa59575a2b382147467",
       "tabbable": null,
       "tooltip": null,
       "value": "Resolving data files: 100%"
      }
     },
     "1f5d91c523064e668805d1129941fa12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_380dd9d521d944d093a293cdbfb4e7a4",
       "placeholder": "​",
       "style": "IPY_MODEL_05d96b601f064a968b95f33035d6d337",
       "tabbable": null,
       "tooltip": null,
       "value": "Batches: 100%"
      }
     },
     "21670d34a44345b2b35184a312808272": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d017156826d943fc912f9ccd2b91ee19",
       "max": 41,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_692884a5ccc145e7a4ae534ce37ad333",
       "tabbable": null,
       "tooltip": null,
       "value": 41
      }
     },
     "380dd9d521d944d093a293cdbfb4e7a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52e518fee2bb4e2891bd4e1ccd8c3278": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5350acd35fbf4114847834509ed00fd2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "680db03bc208418f8711d72bb23e3583": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "692884a5ccc145e7a4ae534ce37ad333": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7bf02b09b2cf49b7bc07fff7c1a8b142": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_14e8a09c7c20442f9703eeb164b4a1a6",
        "IPY_MODEL_21670d34a44345b2b35184a312808272",
        "IPY_MODEL_9fcc9c4a7e9c4bcc9191ca6557d6990e"
       ],
       "layout": "IPY_MODEL_0dcf25c6cd08446b9a120eed74dc93fb",
       "tabbable": null,
       "tooltip": null
      }
     },
     "99f9b52646ab4862ac2acd8c5a6d3f3d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9fcc9c4a7e9c4bcc9191ca6557d6990e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_01a547928418426fac574f40e413bac1",
       "placeholder": "​",
       "style": "IPY_MODEL_52e518fee2bb4e2891bd4e1ccd8c3278",
       "tabbable": null,
       "tooltip": null,
       "value": " 41/41 [00:00&lt;00:00, 5298.45it/s]"
      }
     },
     "a156852c8f074d59b0053b7cb69dd086": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cac4d9f8e96e4ef3a5fdfa41c03b7221": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1f5d91c523064e668805d1129941fa12",
        "IPY_MODEL_f9cfaba2e4a44f13a3b9a16f0b50edd0",
        "IPY_MODEL_f6461e66beb346f78df2c852834185c3"
       ],
       "layout": "IPY_MODEL_083e18f034c4471a895dc999f4d49f7c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d017156826d943fc912f9ccd2b91ee19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f248f9e1ca664aa59575a2b382147467": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f6461e66beb346f78df2c852834185c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5350acd35fbf4114847834509ed00fd2",
       "placeholder": "​",
       "style": "IPY_MODEL_05b7cdf673094a07b39748565af0dbd4",
       "tabbable": null,
       "tooltip": null,
       "value": " 313/313 [10:23&lt;00:00,  1.68it/s]"
      }
     },
     "f9cfaba2e4a44f13a3b9a16f0b50edd0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_680db03bc208418f8711d72bb23e3583",
       "max": 313,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a156852c8f074d59b0053b7cb69dd086",
       "tabbable": null,
       "tooltip": null,
       "value": 313
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}