{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 63. BGE-M3 ITQ・Pivot評価\n",
    "\n",
    "## 目的\n",
    "- `BAAI/bge-m3` (1024次元) での埋め込み生成とITQ/Pivot学習\n",
    "- 10,000件Wikipediaデータでの評価\n",
    "- 学習済みデータの保存（ITQモデル、Pivot重心点）\n",
    "\n",
    "## 出力ファイル\n",
    "- `data/itq_bge_m3_128bits.pkl` - ITQモデル\n",
    "- `data/10k_bge_m3_hashes_128bits.npy` - ハッシュ\n",
    "- `data/pivots_8_bge_m3.npy` - 8ピボット\n",
    "- `data/10k_bge_m3_pivot_distances.npy` - ピボット距離\n",
    "- `data/10k_bge_m3_embeddings.npy` - 埋め込み\n",
    "\n",
    "## 注意\n",
    "- BGE-M3は1024次元の大きなモデル\n",
    "- ITQ 128bitsでは約12.5%の次元を保持"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:41:00.755575Z",
     "iopub.status.busy": "2026-02-04T05:41:00.755420Z",
     "iopub.status.idle": "2026-02-04T05:41:02.028987Z",
     "shell.execute_reply": "2026-02-04T05:41:02.028393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0+cu128\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from itq_lsh import ITQLSH, hamming_distance_batch\n",
    "\n",
    "# GPU確認\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# モデル設定\n",
    "MODEL_NAME = \"BAAI/bge-m3\"\n",
    "MODEL_SHORT = \"bge_m3\"\n",
    "EMBEDDING_DIM = 1024\n",
    "N_SAMPLES = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データ準備（10,000件サンプリング）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:41:02.054033Z",
     "iopub.status.busy": "2026-02-04T05:41:02.053751Z",
     "iopub.status.idle": "2026-02-04T05:41:05.568042Z",
     "shell.execute_reply": "2026-02-04T05:41:05.567536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Wikipedia Japanese dataset (streaming)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded in 3.1s\n"
     ]
    }
   ],
   "source": [
    "# 既存のWikipediaデータからテキストを取得\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading Wikipedia Japanese dataset (streaming)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "wiki_ja = load_dataset(\n",
    "    \"wikimedia/wikipedia\",\n",
    "    \"20231101.ja\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded in {time.time() - start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:41:05.569666Z",
     "iopub.status.busy": "2026-02-04T05:41:05.569392Z",
     "iopub.status.idle": "2026-02-04T05:41:20.329726Z",
     "shell.execute_reply": "2026-02-04T05:41:20.329121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting 10,000 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:   0%|          | 1/10000 [00:03<9:29:54,  3.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  10%|▉         | 971/10000 [00:03<00:23, 389.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  15%|█▌        | 1542/10000 [00:06<00:32, 263.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  25%|██▍       | 2477/10000 [00:06<00:14, 529.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  34%|███▍      | 3437/10000 [00:06<00:07, 893.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  41%|████▏     | 4143/10000 [00:09<00:10, 549.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  52%|█████▏    | 5170/10000 [00:09<00:05, 875.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  62%|██████▏   | 6210/10000 [00:09<00:02, 1310.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  70%|███████   | 7001/10000 [00:11<00:04, 720.05it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  80%|████████  | 8011/10000 [00:11<00:01, 1052.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  91%|█████████ | 9055/10000 [00:11<00:00, 1504.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting:  99%|█████████▉| 9906/10000 [00:11<00:00, 1956.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Collecting: 100%|██████████| 10000/10000 [00:14<00:00, 677.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collected 9,990 documents in 14.8s\n",
      "Sample title: アンパサンド\n",
      "Sample text (first 100 chars): アンパサンド（&, ）は、並立助詞「…と…」を意味する記号である。ラテン語で「…と…」を表す接続詞 \"et\" の合字を起源とする。現代のフォントでも、Trebuchet MS など一部のフォントでは、...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 10,000件を収集\n",
    "print(f\"Collecting {N_SAMPLES:,} documents...\")\n",
    "start_time = time.time()\n",
    "\n",
    "documents = []\n",
    "titles = []\n",
    "\n",
    "for i, item in enumerate(tqdm(wiki_ja, total=N_SAMPLES, desc=\"Collecting\")):\n",
    "    if i >= N_SAMPLES:\n",
    "        break\n",
    "    \n",
    "    # テキストの前処理（最初の500文字程度を使用）\n",
    "    text = item['text'][:500].strip()\n",
    "    if len(text) < 50:  # 短すぎるものはスキップ\n",
    "        continue\n",
    "    \n",
    "    documents.append(text)\n",
    "    titles.append(item['title'])\n",
    "\n",
    "print(f\"\\nCollected {len(documents):,} documents in {time.time() - start_time:.1f}s\")\n",
    "print(f\"Sample title: {titles[0]}\")\n",
    "print(f\"Sample text (first 100 chars): {documents[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 埋め込み生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:41:20.331120Z",
     "iopub.status.busy": "2026-02-04T05:41:20.330953Z",
     "iopub.status.idle": "2026-02-04T05:41:28.027990Z",
     "shell.execute_reply": "2026-02-04T05:41:28.027328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: BAAI/bge-m3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded in 5.8s\n",
      "Device: cuda\n",
      "Embedding dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# モデルロード\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "start_time = time.time()\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded in {time.time() - start_time:.1f}s\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:41:28.029515Z",
     "iopub.status.busy": "2026-02-04T05:41:28.029228Z",
     "iopub.status.idle": "2026-02-04T05:42:37.485741Z",
     "shell.execute_reply": "2026-02-04T05:42:37.485162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for 9,990 documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a4e388d3ac4cef8be79065054475df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding generation completed!\n",
      "Time: 69.5s\n",
      "Speed: 143.8 docs/sec\n",
      "Shape: (9990, 1024)\n"
     ]
    }
   ],
   "source": [
    "# 埋め込み生成\n",
    "print(f\"\\nGenerating embeddings for {len(documents):,} documents...\")\n",
    "start_time = time.time()\n",
    "\n",
    "embeddings = model.encode(\n",
    "    documents,\n",
    "    batch_size=32,  # BGE-M3は大きいのでバッチサイズを小さく\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nEmbedding generation completed!\")\n",
    "print(f\"Time: {elapsed:.1f}s\")\n",
    "print(f\"Speed: {len(documents)/elapsed:.1f} docs/sec\")\n",
    "print(f\"Shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:37.487008Z",
     "iopub.status.busy": "2026-02-04T05:42:37.486874Z",
     "iopub.status.idle": "2026-02-04T05:42:37.511411Z",
     "shell.execute_reply": "2026-02-04T05:42:37.510757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings: ../data/10k_bge_m3_embeddings.npy (39.0 MB)\n"
     ]
    }
   ],
   "source": [
    "# 埋め込みを保存\n",
    "EMB_PATH = DATA_DIR / f\"10k_{MODEL_SHORT}_embeddings.npy\"\n",
    "np.save(EMB_PATH, embeddings)\n",
    "print(f\"Saved embeddings: {EMB_PATH} ({EMB_PATH.stat().st_size / 1024**2:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ITQ学習と保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:37.512740Z",
     "iopub.status.busy": "2026-02-04T05:42:37.512614Z",
     "iopub.status.idle": "2026-02-04T05:42:38.367170Z",
     "shell.execute_reply": "2026-02-04T05:42:38.366672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ITQ with 128 bits...\n",
      "ITQ学習開始: samples=9990, dim=1024, bits=128\n",
      "  Centering完了: mean_norm=0.5552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PCA完了: explained_variance=68.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ITQ iteration 10: quantization_error=0.9026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ITQ iteration 20: quantization_error=0.9020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ITQ iteration 30: quantization_error=0.9017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ITQ iteration 40: quantization_error=0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ITQ iteration 50: quantization_error=0.9015\n",
      "ITQ学習完了\n",
      "\n",
      "Training time: 0.9s\n"
     ]
    }
   ],
   "source": [
    "# ITQ学習 (128 bits)\n",
    "N_BITS = 128\n",
    "\n",
    "print(f\"Training ITQ with {N_BITS} bits...\")\n",
    "start_time = time.time()\n",
    "\n",
    "itq = ITQLSH(n_bits=N_BITS, n_iterations=50, seed=42)\n",
    "itq.fit(embeddings)\n",
    "\n",
    "print(f\"\\nTraining time: {time.time() - start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:38.373175Z",
     "iopub.status.busy": "2026-02-04T05:42:38.372890Z",
     "iopub.status.idle": "2026-02-04T05:42:38.377589Z",
     "shell.execute_reply": "2026-02-04T05:42:38.376822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ITQ model: ../data/itq_bge_m3_128bits.pkl\n"
     ]
    }
   ],
   "source": [
    "# ITQモデルを保存\n",
    "ITQ_PATH = DATA_DIR / f\"itq_{MODEL_SHORT}_{N_BITS}bits.pkl\"\n",
    "itq.save(str(ITQ_PATH))\n",
    "print(f\"Saved ITQ model: {ITQ_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:38.379018Z",
     "iopub.status.busy": "2026-02-04T05:42:38.378857Z",
     "iopub.status.idle": "2026-02-04T05:42:38.397007Z",
     "shell.execute_reply": "2026-02-04T05:42:38.396369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating hashes...\n",
      "Hashes shape: (9990, 128), time: 0.01s\n",
      "Saved hashes: ../data/10k_bge_m3_hashes_128bits.npy\n"
     ]
    }
   ],
   "source": [
    "# ハッシュを生成して保存\n",
    "print(\"Generating hashes...\")\n",
    "start_time = time.time()\n",
    "\n",
    "hashes = itq.transform(embeddings)\n",
    "print(f\"Hashes shape: {hashes.shape}, time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "HASH_PATH = DATA_DIR / f\"10k_{MODEL_SHORT}_hashes_{N_BITS}bits.npy\"\n",
    "np.save(HASH_PATH, hashes)\n",
    "print(f\"Saved hashes: {HASH_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pivot選択と保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:38.399138Z",
     "iopub.status.busy": "2026-02-04T05:42:38.398962Z",
     "iopub.status.idle": "2026-02-04T05:42:38.407324Z",
     "shell.execute_reply": "2026-02-04T05:42:38.404184Z"
    }
   },
   "outputs": [],
   "source": [
    "# ヘルパー関数\n",
    "def hamming_distance(h1: np.ndarray, h2: np.ndarray) -> int:\n",
    "    \"\"\"2つのハッシュ間のハミング距離\"\"\"\n",
    "    return np.sum(h1 != h2)\n",
    "\n",
    "def hamming_distance_to_all(query_hash: np.ndarray, all_hashes: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"クエリと全ドキュメントのハミング距離を計算\"\"\"\n",
    "    return np.sum(query_hash != all_hashes, axis=1)\n",
    "\n",
    "def select_pivots_furthest_first(hashes: np.ndarray, n_pivots: int, seed: int = 42) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Furthest First法でピボットを選択\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_samples = len(hashes)\n",
    "    \n",
    "    sample_size = min(10000, n_samples)\n",
    "    sample_indices = rng.choice(n_samples, sample_size, replace=False)\n",
    "    sample_hashes = hashes[sample_indices]\n",
    "    \n",
    "    pivot_indices = [rng.integers(sample_size)]\n",
    "    pivots = [sample_hashes[pivot_indices[0]]]\n",
    "    \n",
    "    for _ in range(n_pivots - 1):\n",
    "        min_dists = np.full(sample_size, np.inf)\n",
    "        for pivot in pivots:\n",
    "            dists = hamming_distance_to_all(pivot, sample_hashes)\n",
    "            min_dists = np.minimum(min_dists, dists)\n",
    "        \n",
    "        min_dists[pivot_indices] = -1\n",
    "        new_idx = np.argmax(min_dists)\n",
    "        pivot_indices.append(new_idx)\n",
    "        pivots.append(sample_hashes[new_idx])\n",
    "    \n",
    "    return np.array(pivots)\n",
    "\n",
    "def compute_pivot_distances(hashes: np.ndarray, pivots: np.ndarray) -> np.ndarray:\n",
    "    n_samples = len(hashes)\n",
    "    n_pivots = len(pivots)\n",
    "    \n",
    "    distances = np.zeros((n_samples, n_pivots), dtype=np.uint8)\n",
    "    for i, pivot in enumerate(tqdm(pivots, desc=\"Computing pivot distances\")):\n",
    "        distances[:, i] = hamming_distance_to_all(pivot, hashes)\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:38.408922Z",
     "iopub.status.busy": "2026-02-04T05:42:38.408761Z",
     "iopub.status.idle": "2026-02-04T05:42:38.444374Z",
     "shell.execute_reply": "2026-02-04T05:42:38.443914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 8 pivots using Furthest First method...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivots shape: (8, 128)\n",
      "Pivot-to-pivot distances: min=64, max=87, mean=69.8\n"
     ]
    }
   ],
   "source": [
    "# 8ピボットを選択\n",
    "N_PIVOTS = 8\n",
    "\n",
    "print(f\"Selecting {N_PIVOTS} pivots using Furthest First method...\")\n",
    "pivots = select_pivots_furthest_first(hashes, N_PIVOTS)\n",
    "print(f\"Pivots shape: {pivots.shape}\")\n",
    "\n",
    "# ピボット間の距離を確認\n",
    "pivot_dists = []\n",
    "for i in range(N_PIVOTS):\n",
    "    for j in range(i+1, N_PIVOTS):\n",
    "        pivot_dists.append(hamming_distance(pivots[i], pivots[j]))\n",
    "print(f\"Pivot-to-pivot distances: min={min(pivot_dists)}, max={max(pivot_dists)}, mean={np.mean(pivot_dists):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:38.446104Z",
     "iopub.status.busy": "2026-02-04T05:42:38.445936Z",
     "iopub.status.idle": "2026-02-04T05:42:38.451362Z",
     "shell.execute_reply": "2026-02-04T05:42:38.450448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pivots: ../data/pivots_8_bge_m3.npy\n"
     ]
    }
   ],
   "source": [
    "# ピボットを保存\n",
    "PIVOT_PATH = DATA_DIR / f\"pivots_8_{MODEL_SHORT}.npy\"\n",
    "np.save(PIVOT_PATH, pivots)\n",
    "print(f\"Saved pivots: {PIVOT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:38.452795Z",
     "iopub.status.busy": "2026-02-04T05:42:38.452638Z",
     "iopub.status.idle": "2026-02-04T05:42:38.467527Z",
     "shell.execute_reply": "2026-02-04T05:42:38.466911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pivot distances for all documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing pivot distances:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing pivot distances: 100%|██████████| 8/8 [00:00<00:00, 1326.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot distances shape: (9990, 8)\n",
      "Saved pivot distances: ../data/10k_bge_m3_pivot_distances.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 全文書のピボット距離を計算して保存\n",
    "print(\"Computing pivot distances for all documents...\")\n",
    "pivot_distances = compute_pivot_distances(hashes, pivots)\n",
    "print(f\"Pivot distances shape: {pivot_distances.shape}\")\n",
    "\n",
    "PIVOT_DIST_PATH = DATA_DIR / f\"10k_{MODEL_SHORT}_pivot_distances.npy\"\n",
    "np.save(PIVOT_DIST_PATH, pivot_distances)\n",
    "print(f\"Saved pivot distances: {PIVOT_DIST_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 評価（Recall@10, Filter Recall）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:38.469063Z",
     "iopub.status.busy": "2026-02-04T05:42:38.468926Z",
     "iopub.status.idle": "2026-02-04T05:42:38.475801Z",
     "shell.execute_reply": "2026-02-04T05:42:38.475355Z"
    }
   },
   "outputs": [],
   "source": [
    "def pivot_filter(query_hash: np.ndarray, pivots: np.ndarray, \n",
    "                 all_pivot_distances: np.ndarray, threshold: int) -> np.ndarray:\n",
    "    n_docs, n_pivots = all_pivot_distances.shape\n",
    "    query_pivot_dists = np.array([hamming_distance(query_hash, p) for p in pivots])\n",
    "    \n",
    "    mask = np.ones(n_docs, dtype=bool)\n",
    "    for i in range(n_pivots):\n",
    "        lower = query_pivot_dists[i] - threshold\n",
    "        upper = query_pivot_dists[i] + threshold\n",
    "        mask &= (all_pivot_distances[:, i] >= lower) & (all_pivot_distances[:, i] <= upper)\n",
    "    \n",
    "    return np.where(mask)[0]\n",
    "\n",
    "def evaluate_model(\n",
    "    embeddings: np.ndarray,\n",
    "    hashes: np.ndarray,\n",
    "    pivots: np.ndarray,\n",
    "    pivot_distances: np.ndarray,\n",
    "    thresholds: list = [15, 20],\n",
    "    n_queries: int = 100,\n",
    "    top_k: int = 10,\n",
    "    candidate_limits: list = [100, 500, 1000]\n",
    "):\n",
    "    n_docs = len(embeddings)\n",
    "    query_indices = np.random.choice(n_docs, n_queries, replace=False)\n",
    "    \n",
    "    print(f\"Computing ground truth for {n_queries} queries...\")\n",
    "    ground_truth = []\n",
    "    for q_idx in tqdm(query_indices, desc=\"Ground truth\"):\n",
    "        sims = embeddings @ embeddings[q_idx]\n",
    "        sims[q_idx] = -1\n",
    "        top_indices = np.argsort(sims)[-top_k:][::-1]\n",
    "        ground_truth.append(set(top_indices))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # ベースライン\n",
    "    print(\"\\nEvaluating baseline (no filter)...\")\n",
    "    baseline_recalls = {limit: [] for limit in candidate_limits}\n",
    "    \n",
    "    for i, q_idx in enumerate(tqdm(query_indices, desc=\"Baseline\")):\n",
    "        query_hash = hashes[q_idx]\n",
    "        distances = hamming_distance_batch(query_hash, hashes)\n",
    "        distances[q_idx] = 999\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        \n",
    "        for limit in candidate_limits:\n",
    "            top_candidates = set(sorted_indices[:limit])\n",
    "            recall = len(top_candidates & ground_truth[i]) / top_k\n",
    "            baseline_recalls[limit].append(recall)\n",
    "    \n",
    "    baseline_result = {\n",
    "        'method': 'Baseline (no filter)',\n",
    "        'threshold': '-',\n",
    "        'reduction_rate': 0.0,\n",
    "        'filter_recall': 1.0,\n",
    "    }\n",
    "    for limit in candidate_limits:\n",
    "        baseline_result[f'recall@{top_k}_limit{limit}'] = np.mean(baseline_recalls[limit])\n",
    "    results.append(baseline_result)\n",
    "    \n",
    "    # Pivotフィルタリング\n",
    "    for threshold in thresholds:\n",
    "        print(f\"\\nEvaluating Pivot filter (threshold={threshold})...\")\n",
    "        \n",
    "        step1_candidates_list = []\n",
    "        recalls = {limit: [] for limit in candidate_limits}\n",
    "        filter_recall = []\n",
    "        \n",
    "        for i, q_idx in enumerate(tqdm(query_indices, desc=f\"Pivot t={threshold}\")):\n",
    "            candidates = pivot_filter(hashes[q_idx], pivots, pivot_distances, threshold)\n",
    "            candidates = candidates[candidates != q_idx]\n",
    "            step1_candidates_list.append(len(candidates))\n",
    "            \n",
    "            gt_in_candidates = len(ground_truth[i] & set(candidates)) / top_k\n",
    "            filter_recall.append(gt_in_candidates)\n",
    "            \n",
    "            if len(candidates) == 0:\n",
    "                for limit in candidate_limits:\n",
    "                    recalls[limit].append(0.0)\n",
    "                continue\n",
    "            \n",
    "            query_hash = hashes[q_idx]\n",
    "            candidate_hashes = hashes[candidates]\n",
    "            distances = hamming_distance_batch(query_hash, candidate_hashes)\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            \n",
    "            for limit in candidate_limits:\n",
    "                if len(sorted_indices) < limit:\n",
    "                    top_candidates = set(candidates[sorted_indices])\n",
    "                else:\n",
    "                    top_candidates = set(candidates[sorted_indices[:limit]])\n",
    "                \n",
    "                recall = len(top_candidates & ground_truth[i]) / top_k\n",
    "                recalls[limit].append(recall)\n",
    "        \n",
    "        result = {\n",
    "            'method': f'Pivot t={threshold}',\n",
    "            'threshold': threshold,\n",
    "            'reduction_rate': 1 - np.mean(step1_candidates_list) / n_docs,\n",
    "            'filter_recall': np.mean(filter_recall),\n",
    "        }\n",
    "        for limit in candidate_limits:\n",
    "            result[f'recall@{top_k}_limit{limit}'] = np.mean(recalls[limit])\n",
    "        results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:38.477315Z",
     "iopub.status.busy": "2026-02-04T05:42:38.477172Z",
     "iopub.status.idle": "2026-02-04T05:42:38.936018Z",
     "shell.execute_reply": "2026-02-04T05:42:38.935384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ground truth for 100 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Ground truth:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Ground truth:  76%|███████▌  | 76/100 [00:00<00:00, 757.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Ground truth: 100%|██████████| 100/100 [00:00<00:00, 743.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating baseline (no filter)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Baseline:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Baseline:  90%|█████████ | 90/100 [00:00<00:00, 899.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Baseline: 100%|██████████| 100/100 [00:00<00:00, 923.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Pivot filter (threshold=15)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pivot t=15:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pivot t=15: 100%|██████████| 100/100 [00:00<00:00, 1221.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Pivot filter (threshold=20)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pivot t=20:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pivot t=20:  86%|████████▌ | 86/100 [00:00<00:00, 851.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pivot t=20: 100%|██████████| 100/100 [00:00<00:00, 840.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 評価実行\n",
    "results = evaluate_model(\n",
    "    embeddings, hashes, pivots, pivot_distances,\n",
    "    thresholds=[15, 20],\n",
    "    n_queries=100,\n",
    "    top_k=10,\n",
    "    candidate_limits=[100, 500, 1000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:38.937350Z",
     "iopub.status.busy": "2026-02-04T05:42:38.937184Z",
     "iopub.status.idle": "2026-02-04T05:42:38.943585Z",
     "shell.execute_reply": "2026-02-04T05:42:38.943120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BGE-M3 (1024次元) 評価結果\n",
      "================================================================================\n",
      "              method threshold  reduction_rate  filter_recall  recall@10_limit100  recall@10_limit500  recall@10_limit1000\n",
      "Baseline (no filter)         -        0.000000          1.000               0.854               0.986                0.996\n",
      "          Pivot t=15        15        0.624123          0.915               0.808               0.913                0.914\n",
      "          Pivot t=20        20        0.326546          0.992               0.857               0.979                0.988\n"
     ]
    }
   ],
   "source": [
    "# 結果表示\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BGE-M3 ({EMBEDDING_DIM}次元) 評価結果\")\n",
    "print(f\"{'='*80}\")\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. サマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T05:42:38.945110Z",
     "iopub.status.busy": "2026-02-04T05:42:38.944975Z",
     "iopub.status.idle": "2026-02-04T05:42:38.948800Z",
     "shell.execute_reply": "2026-02-04T05:42:38.948171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BGE-M3 ITQ/Pivot Evaluation - Summary\n",
      "============================================================\n",
      "Model: BAAI/bge-m3\n",
      "Embedding dimension: 1024\n",
      "Documents: 9,990\n",
      "ITQ bits: 128\n",
      "Pivots: 8\n",
      "\n",
      "Saved files:\n",
      "  - 10k_bge_m3_embeddings.npy\n",
      "  - itq_bge_m3_128bits.pkl\n",
      "  - 10k_bge_m3_hashes_128bits.npy\n",
      "  - pivots_8_bge_m3.npy\n",
      "  - 10k_bge_m3_pivot_distances.npy\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"BGE-M3 ITQ/Pivot Evaluation - Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Embedding dimension: {EMBEDDING_DIM}\")\n",
    "print(f\"Documents: {len(documents):,}\")\n",
    "print(f\"ITQ bits: {N_BITS}\")\n",
    "print(f\"Pivots: {N_PIVOTS}\")\n",
    "print(f\"\")\n",
    "print(f\"Saved files:\")\n",
    "print(f\"  - {EMB_PATH.name}\")\n",
    "print(f\"  - {ITQ_PATH.name}\")\n",
    "print(f\"  - {HASH_PATH.name}\")\n",
    "print(f\"  - {PIVOT_PATH.name}\")\n",
    "print(f\"  - {PIVOT_DIST_PATH.name}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 7. 実験結果サマリー\n\n### モデル情報\n| 項目 | 値 |\n|------|-----|\n| モデル名 | BAAI/bge-m3 |\n| 埋め込み次元 | 1024 |\n| ドキュメント数 | 9,990 |\n| ITQビット数 | 128 bits |\n| ピボット数 | 8 |\n\n### 評価結果\n\n| 手法 | 削減率 | Filter Recall | Recall@10 (lim100) | Recall@10 (lim500) | Recall@10 (lim1000) |\n|------|--------|---------------|--------------------|--------------------|---------------------|\n| Baseline | 0% | 100% | 85.4% | 98.6% | **99.6%** |\n| Pivot t=15 | **62.4%** | 91.5% | 80.8% | 91.3% | 91.4% |\n| Pivot t=20 | 32.7% | **99.2%** | 85.7% | 97.9% | 98.8% |\n\n### 保存ファイル一覧\n- `data/10k_bge_m3_embeddings.npy` - 埋め込みベクトル (39.0 MB)\n- `data/itq_bge_m3_128bits.pkl` - ITQ学習済みモデル\n- `data/10k_bge_m3_hashes_128bits.npy` - 128bitハッシュ\n- `data/pivots_8_bge_m3.npy` - 8ピボット\n- `data/10k_bge_m3_pivot_distances.npy` - ピボット距離\n\n### 考察\n- BGE-M3は1024次元の大きなモデルで、最高のRecall（99.6%）を達成\n- Pivot t=20で約33%削減しながら98.8%のRecallを維持（3モデル中最高）\n- 埋め込み生成速度は143.8 docs/sec（他モデルの約1/4〜1/6）\n- 1024次元→128 bitsで約12.5%の情報を保持するが、依然として高い精度",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1332948aa7ed48ffb5acbaafe0af9f0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "17fb7a819255413784a33106d76bb48b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3312742134404eb1a5f492f212d84360": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c0e09205c4df493ca27a8f673fda607e",
       "max": 313,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1332948aa7ed48ffb5acbaafe0af9f0d",
       "tabbable": null,
       "tooltip": null,
       "value": 313
      }
     },
     "3daf70eac43c48ebabc9b5803e9aafdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_17fb7a819255413784a33106d76bb48b",
       "placeholder": "​",
       "style": "IPY_MODEL_f94d76464adb4f879629de15c58cf884",
       "tabbable": null,
       "tooltip": null,
       "value": " 313/313 [01:09&lt;00:00, 15.18it/s]"
      }
     },
     "400ec9a7be6b430c812c7b5c2bca8ea9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "71a4e388d3ac4cef8be79065054475df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7ea4a03e60f4476b843d623dcf28c730",
        "IPY_MODEL_3312742134404eb1a5f492f212d84360",
        "IPY_MODEL_3daf70eac43c48ebabc9b5803e9aafdc"
       ],
       "layout": "IPY_MODEL_fa2cdfa0129044daa43552ab8412d16c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7ea4a03e60f4476b843d623dcf28c730": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f0165b8d815e48469569ba6498a51675",
       "placeholder": "​",
       "style": "IPY_MODEL_400ec9a7be6b430c812c7b5c2bca8ea9",
       "tabbable": null,
       "tooltip": null,
       "value": "Batches: 100%"
      }
     },
     "c0e09205c4df493ca27a8f673fda607e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0165b8d815e48469569ba6498a51675": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f94d76464adb4f879629de15c58cf884": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fa2cdfa0129044daa43552ab8412d16c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}