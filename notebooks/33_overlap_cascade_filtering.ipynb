{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 33. オーバーラップセグメントによる3段階カスケード枝刈り\n",
    "\n",
    "## 目的\n",
    "\n",
    "実験32で有効性が確認されたOverlap(8/4)をベースに、実験30と同様の3段階枝刈り方式を検証する。\n",
    "\n",
    "## 3段階枝刈りフロー\n",
    "\n",
    "```\n",
    "全データ (400,000件)\n",
    "    ↓ Step 1: Overlapセグメント一致フィルタ\n",
    "候補 (~5,000件)\n",
    "    ↓ Step 2: ハミング距離ソート\n",
    "候補 (~500件)\n",
    "    ↓ Step 3: コサイン類似度\n",
    "Top-K 結果\n",
    "```\n",
    "\n",
    "## 検証するOverlap設定\n",
    "\n",
    "| 設定 | セグメント幅 | ストライド | セグメント数 | バケットサイズ |\n",
    "|------|------------|-----------|-------------|---------------|\n",
    "| (8, 4) | 8bit | 4bit | 31 | 約1,562件 |\n",
    "| (8, 2) | 8bit | 2bit | 61 | 約1,562件 |\n",
    "| (16, 8) | 16bit | 8bit | 15 | 約8.7件 |\n",
    "| (16, 4) | 16bit | 4bit | 29 | 約8.7件 |\n",
    "\n",
    "## 評価指標\n",
    "\n",
    "- Recall@5, @10, @20\n",
    "- 各Stepでの候補数\n",
    "- 処理時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "from src.itq_lsh import ITQLSH, hamming_distance_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パス設定\n",
    "DB_PATH = '../data/experiment_400k.duckdb'\n",
    "ITQ_MODEL_PATH = '../data/itq_model.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ読み込み中...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88391a2a69194b56bc8827522845f853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "読み込み完了: 400,000件\n",
      "埋め込み shape: (400000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# データ読み込み\n",
    "print('データ読み込み中...')\n",
    "conn = duckdb.connect(DB_PATH, read_only=True)\n",
    "\n",
    "result = conn.execute(\"\"\"\n",
    "    SELECT id, embedding\n",
    "    FROM documents\n",
    "    ORDER BY id\n",
    "\"\"\").fetchall()\n",
    "conn.close()\n",
    "\n",
    "doc_ids = np.array([r[0] for r in result])\n",
    "embeddings = np.array([r[1] for r in result], dtype=np.float32)\n",
    "\n",
    "print(f'読み込み完了: {len(doc_ids):,}件')\n",
    "print(f'埋め込み shape: {embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITQモデル読み込み中...\n",
      "ITQハッシュ計算中...\n",
      "ハッシュ shape: (400000, 128)\n"
     ]
    }
   ],
   "source": [
    "# ITQモデル読み込みとハッシュ計算\n",
    "print('ITQモデル読み込み中...')\n",
    "itq = ITQLSH.load(ITQ_MODEL_PATH)\n",
    "\n",
    "print('ITQハッシュ計算中...')\n",
    "hashes = itq.transform(embeddings)\n",
    "print(f'ハッシュ shape: {hashes.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 共通ユーティリティ関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ground_truth(query_embedding, all_embeddings, top_k=20):\n",
    "    \"\"\"ブルートフォースでGround Truthを計算\"\"\"\n",
    "    query_norm = norm(query_embedding)\n",
    "    all_norms = norm(all_embeddings, axis=1)\n",
    "    cosines = (all_embeddings @ query_embedding) / (all_norms * query_norm + 1e-10)\n",
    "    top_indices = np.argsort(cosines)[-top_k:][::-1]\n",
    "    return top_indices\n",
    "\n",
    "\n",
    "def evaluate_method(test_query_indices, predicted_results, ground_truths, top_k_values=[5, 10, 20]):\n",
    "    \"\"\"Recall評価\"\"\"\n",
    "    recalls = {k: [] for k in top_k_values}\n",
    "    \n",
    "    for qi in test_query_indices:\n",
    "        gt = ground_truths[qi]\n",
    "        pred = predicted_results[qi]\n",
    "        \n",
    "        for k in top_k_values:\n",
    "            gt_set = set(gt[:k])\n",
    "            pred_set = set(pred[:k]) if len(pred) >= k else set(pred)\n",
    "            recalls[k].append(len(gt_set & pred_set) / k)\n",
    "    \n",
    "    return {f'recall@{k}': np.mean(v) for k, v in recalls.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストクエリ数: 100\n",
      "Ground Truth計算中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GT計算: 100%|██████████| 100/100 [00:33<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# テスト用クエリを準備\n",
    "rng = np.random.default_rng(42)\n",
    "n_test_queries = 100\n",
    "test_query_indices = rng.choice(len(embeddings), n_test_queries, replace=False)\n",
    "\n",
    "print(f'テストクエリ数: {n_test_queries}')\n",
    "\n",
    "# Ground Truth計算\n",
    "print('Ground Truth計算中...')\n",
    "ground_truths = {}\n",
    "for qi in tqdm(test_query_indices, desc='GT計算'):\n",
    "    ground_truths[qi] = compute_ground_truth(embeddings[qi], embeddings, top_k=20)\n",
    "print('完了')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. オーバーラップセグメントインデックスの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_to_overlap_segments(hash_array, segment_width=8, stride=4):\n",
    "    \"\"\"\n",
    "    オーバーラップセグメントを生成\n",
    "    \n",
    "    Args:\n",
    "        hash_array: (n_docs, 128) のハッシュ配列\n",
    "        segment_width: セグメント幅（ビット数）\n",
    "        stride: スライド幅（ビット数）\n",
    "    \n",
    "    Returns:\n",
    "        segments: (n_docs, n_segments) の整数配列\n",
    "        n_segments: セグメント数\n",
    "    \"\"\"\n",
    "    n_docs, n_bits = hash_array.shape\n",
    "    n_segments = (n_bits - segment_width) // stride + 1\n",
    "    \n",
    "    segments = []\n",
    "    for i in range(n_segments):\n",
    "        start = i * stride\n",
    "        end = start + segment_width\n",
    "        segment_bits = hash_array[:, start:end]\n",
    "        \n",
    "        # ビットを整数に変換\n",
    "        powers = 2 ** np.arange(segment_width - 1, -1, -1)\n",
    "        segment_int = np.sum(segment_bits * powers, axis=1)\n",
    "        segments.append(segment_int)\n",
    "    \n",
    "    return np.column_stack(segments), n_segments\n",
    "\n",
    "\n",
    "def build_overlap_index(segments):\n",
    "    \"\"\"\n",
    "    オーバーラップセグメントのインデックスを構築\n",
    "    \"\"\"\n",
    "    n_docs, n_segments = segments.shape\n",
    "    index = {i: defaultdict(list) for i in range(n_segments)}\n",
    "    \n",
    "    for doc_idx in range(n_docs):\n",
    "        for seg_idx in range(n_segments):\n",
    "            seg_value = int(segments[doc_idx, seg_idx])\n",
    "            index[seg_idx][seg_value].append(doc_idx)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "オーバーラップセグメントインデックス構築中...\n",
      "  (8, 4): 31セグメント, 平均バケット: 1562.5件\n",
      "  (8, 2): 61セグメント, 平均バケット: 1562.5件\n",
      "  (16, 8): 15セグメント, 平均バケット: 8.7件\n",
      "  (16, 4): 29セグメント, 平均バケット: 8.7件\n"
     ]
    }
   ],
   "source": [
    "# 複数のOverlap設定でインデックス構築\n",
    "print('オーバーラップセグメントインデックス構築中...')\n",
    "\n",
    "overlap_configs = [\n",
    "    (8, 4),   # 8bit幅、4bitストライド → 31セグメント\n",
    "    (8, 2),   # 8bit幅、2bitストライド → 61セグメント\n",
    "    (16, 8),  # 16bit幅、8bitストライド → 15セグメント\n",
    "    (16, 4),  # 16bit幅、4bitストライド → 29セグメント\n",
    "]\n",
    "\n",
    "overlap_data = {}\n",
    "\n",
    "for width, stride in overlap_configs:\n",
    "    key = (width, stride)\n",
    "    segments, n_seg = hash_to_overlap_segments(hashes, width, stride)\n",
    "    index = build_overlap_index(segments)\n",
    "    \n",
    "    # 統計\n",
    "    bucket_sizes = [len(docs) for seg_idx in index for docs in index[seg_idx].values()]\n",
    "    \n",
    "    overlap_data[key] = {\n",
    "        'segments': segments,\n",
    "        'index': index,\n",
    "        'n_segments': n_seg,\n",
    "        'avg_bucket_size': np.mean(bucket_sizes),\n",
    "    }\n",
    "    \n",
    "    print(f'  ({width}, {stride}): {n_seg}セグメント, 平均バケット: {np.mean(bucket_sizes):.1f}件')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 3段階カスケード枝刈り関数の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1_overlap_filter(query_segments, segment_index, n_segments):\n",
    "    \"\"\"\n",
    "    Step 1: Overlapセグメント一致によるフィルタリング（OR条件）\n",
    "    \n",
    "    いずれかのセグメントが一致したドキュメントを候補とする\n",
    "    \"\"\"\n",
    "    candidates = set()\n",
    "    \n",
    "    for seg_idx in range(n_segments):\n",
    "        seg_value = int(query_segments[seg_idx])\n",
    "        if seg_value in segment_index[seg_idx]:\n",
    "            candidates.update(segment_index[seg_idx][seg_value])\n",
    "    \n",
    "    return np.array(list(candidates))\n",
    "\n",
    "\n",
    "def step2_hamming_filter(query_hash, candidate_indices, all_hashes, top_n):\n",
    "    \"\"\"\n",
    "    Step 2: ハミング距離によるソートと絞り込み\n",
    "    \"\"\"\n",
    "    if len(candidate_indices) == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    \n",
    "    candidate_hashes = all_hashes[candidate_indices]\n",
    "    distances = hamming_distance_batch(query_hash, candidate_hashes)\n",
    "    \n",
    "    top_n = min(top_n, len(candidate_indices))\n",
    "    top_idx_in_candidates = np.argsort(distances)[:top_n]\n",
    "    \n",
    "    return candidate_indices[top_idx_in_candidates]\n",
    "\n",
    "\n",
    "def step3_cosine_rank(query_embedding, candidate_indices, all_embeddings, top_k):\n",
    "    \"\"\"\n",
    "    Step 3: コサイン類似度によるランキング\n",
    "    \"\"\"\n",
    "    if len(candidate_indices) == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    \n",
    "    candidate_embeddings = all_embeddings[candidate_indices]\n",
    "    query_norm = norm(query_embedding)\n",
    "    candidate_norms = norm(candidate_embeddings, axis=1)\n",
    "    \n",
    "    cosine_scores = (candidate_embeddings @ query_embedding) / (candidate_norms * query_norm + 1e-10)\n",
    "    \n",
    "    top_k = min(top_k, len(candidate_indices))\n",
    "    top_idx_in_candidates = np.argsort(cosine_scores)[-top_k:][::-1]\n",
    "    \n",
    "    return candidate_indices[top_idx_in_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cascade_search(\n",
    "    query_embedding,\n",
    "    query_hash,\n",
    "    query_segments,\n",
    "    segment_index,\n",
    "    n_segments,\n",
    "    all_hashes,\n",
    "    all_embeddings,\n",
    "    step1_limit=5000,\n",
    "    step2_limit=500,\n",
    "    top_k=20\n",
    "):\n",
    "    \"\"\"\n",
    "    3段階カスケード検索\n",
    "    \n",
    "    Step 1: Overlapセグメント一致 → step1_limit件\n",
    "    Step 2: ハミング距離ソート → step2_limit件\n",
    "    Step 3: コサイン類似度 → top_k件\n",
    "    \"\"\"\n",
    "    timing = {}\n",
    "    \n",
    "    # Step 1: Overlapセグメント一致フィルタ\n",
    "    t0 = time.time()\n",
    "    step1_candidates = step1_overlap_filter(query_segments, segment_index, n_segments)\n",
    "    step1_raw_count = len(step1_candidates)\n",
    "    \n",
    "    # Step1でstep1_limitを超えた場合はハミング距離で絞る\n",
    "    if len(step1_candidates) > step1_limit:\n",
    "        step1_candidates = step2_hamming_filter(\n",
    "            query_hash, step1_candidates, all_hashes, step1_limit\n",
    "        )\n",
    "    timing['step1_ms'] = (time.time() - t0) * 1000\n",
    "    step1_count = len(step1_candidates)\n",
    "    \n",
    "    # Step 2: ハミング距離ソート\n",
    "    t0 = time.time()\n",
    "    step2_candidates = step2_hamming_filter(\n",
    "        query_hash, step1_candidates, all_hashes, step2_limit\n",
    "    )\n",
    "    timing['step2_ms'] = (time.time() - t0) * 1000\n",
    "    step2_count = len(step2_candidates)\n",
    "    \n",
    "    # Step 3: コサイン類似度ランキング\n",
    "    t0 = time.time()\n",
    "    top_k_indices = step3_cosine_rank(\n",
    "        query_embedding, step2_candidates, all_embeddings, top_k\n",
    "    )\n",
    "    timing['step3_ms'] = (time.time() - t0) * 1000\n",
    "    \n",
    "    timing['total_ms'] = timing['step1_ms'] + timing['step2_ms'] + timing['step3_ms']\n",
    "    \n",
    "    return {\n",
    "        'top_k_indices': top_k_indices,\n",
    "        'step1_raw_count': step1_raw_count,\n",
    "        'step1_count': step1_count,\n",
    "        'step2_count': step2_count,\n",
    "        'timing': timing\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 3段階カスケード検索の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "評価設定数: 12\n"
     ]
    }
   ],
   "source": [
    "# 評価パラメータ設定\n",
    "evaluation_configs = [\n",
    "    # (overlap_config, step1_limit, step2_limit)\n",
    "    # Overlap(8,4) ベース\n",
    "    ((8, 4), 5000, 500),\n",
    "    ((8, 4), 5000, 1000),\n",
    "    ((8, 4), 10000, 500),\n",
    "    ((8, 4), 10000, 1000),\n",
    "    ((8, 4), 10000, 2000),\n",
    "    \n",
    "    # Overlap(8,2) - より多くのセグメント\n",
    "    ((8, 2), 5000, 500),\n",
    "    ((8, 2), 5000, 1000),\n",
    "    ((8, 2), 10000, 1000),\n",
    "    \n",
    "    # Overlap(16,8) - 粗いセグメント\n",
    "    ((16, 8), 2000, 500),\n",
    "    ((16, 8), 5000, 500),\n",
    "    \n",
    "    # Overlap(16,4) - 中間\n",
    "    ((16, 4), 3000, 500),\n",
    "    ((16, 4), 5000, 500),\n",
    "]\n",
    "\n",
    "print(f'評価設定数: {len(evaluation_configs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "3段階カスケード検索評価\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "設定: 100%|██████████| 12/12 [00:23<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "評価完了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# カスケード検索評価\n",
    "print('=' * 80)\n",
    "print('3段階カスケード検索評価')\n",
    "print('=' * 80)\n",
    "\n",
    "cascade_results = []\n",
    "\n",
    "for overlap_config, s1_limit, s2_limit in tqdm(evaluation_configs, desc='設定'):\n",
    "    width, stride = overlap_config\n",
    "    data = overlap_data[overlap_config]\n",
    "    segments = data['segments']\n",
    "    index = data['index']\n",
    "    n_seg = data['n_segments']\n",
    "    \n",
    "    predicted = {}\n",
    "    step1_raw_counts = []\n",
    "    step1_counts = []\n",
    "    step2_counts = []\n",
    "    times = []\n",
    "    \n",
    "    for qi in test_query_indices:\n",
    "        result = cascade_search(\n",
    "            embeddings[qi], hashes[qi], segments[qi],\n",
    "            index, n_seg, hashes, embeddings,\n",
    "            step1_limit=s1_limit, step2_limit=s2_limit, top_k=20\n",
    "        )\n",
    "        \n",
    "        predicted[qi] = result['top_k_indices']\n",
    "        step1_raw_counts.append(result['step1_raw_count'])\n",
    "        step1_counts.append(result['step1_count'])\n",
    "        step2_counts.append(result['step2_count'])\n",
    "        times.append(result['timing']['total_ms'])\n",
    "    \n",
    "    recalls = evaluate_method(test_query_indices, predicted, ground_truths)\n",
    "    \n",
    "    cascade_results.append({\n",
    "        'overlap': f'({width},{stride})',\n",
    "        'width': width,\n",
    "        'stride': stride,\n",
    "        'n_segments': n_seg,\n",
    "        'step1_limit': s1_limit,\n",
    "        'step2_limit': s2_limit,\n",
    "        'avg_step1_raw': np.mean(step1_raw_counts),\n",
    "        'avg_step1': np.mean(step1_counts),\n",
    "        'avg_step2': np.mean(step2_counts),\n",
    "        **recalls,\n",
    "        'avg_time_ms': np.mean(times)\n",
    "    })\n",
    "\n",
    "df_cascade = pd.DataFrame(cascade_results)\n",
    "print('\\n評価完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "3段階カスケード検索結果サマリー\n",
      "========================================================================================================================\n",
      "\n",
      " Overlap |  S1 Lim |  S2 Lim |   S1 Raw |  S1 Act |    S2 |    R@5 |   R@10 |   R@20 |     Time\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "   (8,4) |   10000 |    2000 |    63764 |   10000 |  2000 |  90.4% |  90.0% |  86.6% |   23.46ms\n",
      "   (8,2) |    5000 |    1000 |    86750 |    5000 |  1000 |  85.4% |  84.7% |  79.2% |   29.53ms\n",
      "   (8,2) |   10000 |    1000 |    86750 |   10000 |  1000 |  85.4% |  84.7% |  79.2% |   30.57ms\n",
      "   (8,4) |    5000 |    1000 |    63764 |    5000 |  1000 |  86.4% |  84.5% |  78.7% |   21.28ms\n",
      "   (8,4) |   10000 |    1000 |    63764 |   10000 |  1000 |  86.4% |  84.5% |  78.7% |   22.28ms\n",
      "   (8,2) |    5000 |     500 |    86750 |    5000 |   500 |  78.0% |  74.8% |  68.2% |   29.06ms\n",
      "   (8,4) |   10000 |     500 |    63764 |   10000 |   500 |  77.8% |  74.4% |  67.9% |   21.53ms\n",
      "   (8,4) |    5000 |     500 |    63764 |    5000 |   500 |  77.8% |  74.4% |  67.9% |   20.47ms\n",
      "  (16,4) |    5000 |     500 |     3308 |    2221 |   494 |  53.6% |  46.8% |  39.4% |    2.31ms\n",
      "  (16,4) |    3000 |     500 |     3308 |    1722 |   494 |  53.6% |  46.8% |  39.4% |    2.22ms\n",
      "  (16,8) |    5000 |     500 |     2384 |    1673 |   464 |  47.6% |  41.5% |  34.0% |    1.62ms\n",
      "  (16,8) |    2000 |     500 |     2384 |    1097 |   464 |  47.6% |  41.5% |  34.0% |    1.58ms\n"
     ]
    }
   ],
   "source": [
    "# 結果表示\n",
    "print('\\n' + '=' * 120)\n",
    "print('3段階カスケード検索結果サマリー')\n",
    "print('=' * 120)\n",
    "\n",
    "print(f'\\n{\"Overlap\":>8} | {\"S1 Lim\":>7} | {\"S2 Lim\":>7} | {\"S1 Raw\":>8} | {\"S1 Act\":>7} | {\"S2\":>5} | {\"R@5\":>6} | {\"R@10\":>6} | {\"R@20\":>6} | {\"Time\":>8}')\n",
    "print('-' * 120)\n",
    "\n",
    "# Recall@10でソート\n",
    "df_sorted = df_cascade.sort_values('recall@10', ascending=False)\n",
    "\n",
    "for _, row in df_sorted.iterrows():\n",
    "    print(f'{row[\"overlap\"]:>8} | {row[\"step1_limit\"]:>7} | {row[\"step2_limit\"]:>7} | '\n",
    "          f'{row[\"avg_step1_raw\"]:>8.0f} | {row[\"avg_step1\"]:>7.0f} | {row[\"avg_step2\"]:>5.0f} | '\n",
    "          f'{row[\"recall@5\"]*100:>5.1f}% | {row[\"recall@10\"]*100:>5.1f}% | {row[\"recall@20\"]*100:>5.1f}% | '\n",
    "          f'{row[\"avg_time_ms\"]:>7.2f}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ベースライン（2段階検索）との比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_stage_search(query_embedding, query_hash, all_hashes, all_embeddings, candidates, top_k):\n",
    "    \"\"\"従来の2段階検索（全件ハミング距離→コサイン）\"\"\"\n",
    "    distances = hamming_distance_batch(query_hash, all_hashes)\n",
    "    candidate_indices = np.argsort(distances)[:candidates]\n",
    "    return step3_cosine_rank(query_embedding, candidate_indices, all_embeddings, top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベースライン（2段階検索）評価中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "候補500: 100%|██████████| 100/100 [00:03<00:00, 29.03it/s]\n",
      "候補1000: 100%|██████████| 100/100 [00:03<00:00, 27.96it/s]\n",
      "候補2000: 100%|██████████| 100/100 [00:03<00:00, 27.43it/s]\n",
      "候補5000: 100%|██████████| 100/100 [00:04<00:00, 24.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ベースライン結果:\n",
      "   method  step2_limit  recall@5  recall@10  recall@20  avg_time_ms\n",
      " 2段階(500)          500     0.788      0.750     0.6820    34.184358\n",
      "2段階(1000)         1000     0.860      0.848     0.7950    35.529861\n",
      "2段階(2000)         2000     0.916      0.913     0.8775    36.199548\n",
      "2段階(5000)         5000     0.952      0.960     0.9530    40.268197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ベースライン評価\n",
    "print('ベースライン（2段階検索）評価中...')\n",
    "\n",
    "baseline_results = []\n",
    "for candidates in [500, 1000, 2000, 5000]:\n",
    "    predicted = {}\n",
    "    times = []\n",
    "    \n",
    "    for qi in tqdm(test_query_indices, desc=f'候補{candidates}'):\n",
    "        t0 = time.time()\n",
    "        predicted[qi] = two_stage_search(\n",
    "            embeddings[qi], hashes[qi], hashes, embeddings,\n",
    "            candidates=candidates, top_k=20\n",
    "        )\n",
    "        times.append((time.time() - t0) * 1000)\n",
    "    \n",
    "    recalls = evaluate_method(test_query_indices, predicted, ground_truths)\n",
    "    baseline_results.append({\n",
    "        'method': f'2段階({candidates})',\n",
    "        'step2_limit': candidates,\n",
    "        **recalls,\n",
    "        'avg_time_ms': np.mean(times)\n",
    "    })\n",
    "\n",
    "df_baseline = pd.DataFrame(baseline_results)\n",
    "print('\\nベースライン結果:')\n",
    "print(df_baseline.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. 最終比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "最終比較: 3段階カスケード vs 2段階検索\n",
      "========================================================================================================================\n",
      "\n",
      "■ 3段階カスケード検索（Recall@10上位5件）\n",
      " Overlap |      S1 |    S2 |   R@10 |    削減率 |     Time | 備考\n",
      "------------------------------------------------------------------------------------------\n",
      "   (8,4) |   10000 |  2000 |  90.0% |  97.5% |   23.46ms | \n",
      "   (8,2) |    5000 |  1000 |  84.7% |  98.8% |   29.53ms | \n",
      "   (8,2) |   10000 |  1000 |  84.7% |  97.5% |   30.57ms | \n",
      "   (8,4) |    5000 |  1000 |  84.5% |  98.8% |   21.28ms | \n",
      "   (8,4) |   10000 |  1000 |  84.5% |  97.5% |   22.28ms | \n",
      "\n",
      "■ 2段階検索（ベースライン）\n",
      "             手法 |   R@10 |    削減率 |     Time\n",
      "------------------------------------------------------------\n",
      "       2段階(500) |  75.0% |  99.9% |   34.18ms\n",
      "      2段階(1000) |  84.8% |  99.8% |   35.53ms\n",
      "      2段階(2000) |  91.3% |  99.5% |   36.20ms\n",
      "      2段階(5000) |  96.0% |  98.8% |   40.27ms\n"
     ]
    }
   ],
   "source": [
    "# 最終比較\n",
    "print('\\n' + '=' * 120)\n",
    "print('最終比較: 3段階カスケード vs 2段階検索')\n",
    "print('=' * 120)\n",
    "\n",
    "print('\\n■ 3段階カスケード検索（Recall@10上位5件）')\n",
    "print(f'{\"Overlap\":>8} | {\"S1\":>7} | {\"S2\":>5} | {\"R@10\":>6} | {\"削減率\":>6} | {\"Time\":>8} | 備考')\n",
    "print('-' * 90)\n",
    "\n",
    "for _, row in df_sorted.head(5).iterrows():\n",
    "    reduction = (400000 - row['avg_step1']) / 400000 * 100\n",
    "    note = ''\n",
    "    if row['recall@10'] >= 0.90:\n",
    "        note = '★推奨'\n",
    "    print(f'{row[\"overlap\"]:>8} | {row[\"step1_limit\"]:>7} | {row[\"step2_limit\"]:>5} | '\n",
    "          f'{row[\"recall@10\"]*100:>5.1f}% | {reduction:>5.1f}% | '\n",
    "          f'{row[\"avg_time_ms\"]:>7.2f}ms | {note}')\n",
    "\n",
    "print('\\n■ 2段階検索（ベースライン）')\n",
    "print(f'{\"手法\":>15} | {\"R@10\":>6} | {\"削減率\":>6} | {\"Time\":>8}')\n",
    "print('-' * 60)\n",
    "\n",
    "for _, row in df_baseline.iterrows():\n",
    "    reduction = (400000 - row['step2_limit']) / 400000 * 100\n",
    "    print(f'{row[\"method\"]:>15} | {row[\"recall@10\"]*100:>5.1f}% | {reduction:>5.1f}% | {row[\"avg_time_ms\"]:>7.2f}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Step1での枝刈り効果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Step1（Overlapセグメント一致）での枝刈り効果\n",
      "================================================================================\n",
      "\n",
      "■ Overlap設定別の候補数（Step1 Raw）\n",
      "  Overlap(8,4): 平均候補数 63,764件, 削減率 84.1%\n",
      "  Overlap(8,2): 平均候補数 86,750件, 削減率 78.3%\n",
      "  Overlap(16,8): 平均候補数 2,384件, 削減率 99.4%\n",
      "  Overlap(16,4): 平均候補数 3,308件, 削減率 99.2%\n",
      "\n",
      "■ 考察\n",
      "  - Overlap(8,4/8,2): 候補が多い（6-9万件）→ Step1でさらにハミング距離絞りが必要\n",
      "  - Overlap(16,8/16,4): 候補が少ない（2-3千件）→ Step1で大幅に絞れるが精度低下の可能性\n"
     ]
    }
   ],
   "source": [
    "# Step1での枝刈り効果を分析\n",
    "print('=' * 80)\n",
    "print('Step1（Overlapセグメント一致）での枝刈り効果')\n",
    "print('=' * 80)\n",
    "\n",
    "print('\\n■ Overlap設定別の候補数（Step1 Raw）')\n",
    "for config, data in overlap_data.items():\n",
    "    width, stride = config\n",
    "    rows = df_cascade[df_cascade['overlap'] == f'({width},{stride})']\n",
    "    if len(rows) > 0:\n",
    "        avg_raw = rows['avg_step1_raw'].mean()\n",
    "        reduction = (400000 - avg_raw) / 400000 * 100\n",
    "        print(f'  Overlap({width},{stride}): 平均候補数 {avg_raw:,.0f}件, 削減率 {reduction:.1f}%')\n",
    "\n",
    "print('\\n■ 考察')\n",
    "print('  - Overlap(8,4/8,2): 候補が多い（6-9万件）→ Step1でさらにハミング距離絞りが必要')\n",
    "print('  - Overlap(16,8/16,4): 候補が少ない（2-3千件）→ Step1で大幅に絞れるが精度低下の可能性')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. 結論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "結論\n",
      "================================================================================\n",
      "\n",
      "■ 実験目的\n",
      "  Overlap(8/4)をベースに、実験30と同様の3段階枝刈り方式を検証\n",
      "\n",
      "■ 最良設定（Recall@10）\n",
      "  設定: Overlap(8,4), Step1=10000件, Step2=2000件\n",
      "  Recall@10: 90.0%\n",
      "  Step1候補数: 10000件\n",
      "  処理時間: 23.46ms\n",
      "\n",
      "■ ベースライン（2段階検索）との比較\n",
      "  2段階(2000): Recall@10 = 91.3%, 処理時間 = 36.20ms\n",
      "  3段階最良:   Recall@10 = 90.0%, 処理時間 = 23.46ms\n",
      "\n",
      "  ※ 2段階検索は全件（40万件）のハミング距離を計算\n",
      "  ※ 3段階カスケードはStep1で候補を絞ってからハミング距離を計算\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 最良設定の特定\n",
    "best_cascade = df_sorted.iloc[0]\n",
    "best_90plus = df_sorted[df_sorted['recall@10'] >= 0.90].iloc[0] if len(df_sorted[df_sorted['recall@10'] >= 0.90]) > 0 else None\n",
    "baseline_2000 = df_baseline[df_baseline['step2_limit'] == 2000].iloc[0]\n",
    "\n",
    "print('=' * 80)\n",
    "print('結論')\n",
    "print('=' * 80)\n",
    "\n",
    "print(f'''\n",
    "■ 実験目的\n",
    "  Overlap(8/4)をベースに、実験30と同様の3段階枝刈り方式を検証\n",
    "\n",
    "■ 最良設定（Recall@10）\n",
    "  設定: Overlap{best_cascade[\"overlap\"]}, Step1={best_cascade[\"step1_limit\"]}件, Step2={best_cascade[\"step2_limit\"]}件\n",
    "  Recall@10: {best_cascade[\"recall@10\"]*100:.1f}%\n",
    "  Step1候補数: {best_cascade[\"avg_step1\"]:.0f}件\n",
    "  処理時間: {best_cascade[\"avg_time_ms\"]:.2f}ms\n",
    "''')\n",
    "\n",
    "if best_90plus is not None:\n",
    "    reduction = (400000 - best_90plus['avg_step1']) / 400000 * 100\n",
    "    print(f'''■ Recall@10 ≥ 90%の最小コスト設定\n",
    "  設定: Overlap{best_90plus[\"overlap\"]}, Step1={best_90plus[\"step1_limit\"]}件, Step2={best_90plus[\"step2_limit\"]}件\n",
    "  Recall@10: {best_90plus[\"recall@10\"]*100:.1f}%\n",
    "  Step1候補数: {best_90plus[\"avg_step1\"]:.0f}件（削減率{reduction:.1f}%）\n",
    "  処理時間: {best_90plus[\"avg_time_ms\"]:.2f}ms\n",
    "''')\n",
    "\n",
    "print(f'''■ ベースライン（2段階検索）との比較\n",
    "  2段階(2000): Recall@10 = {baseline_2000[\"recall@10\"]*100:.1f}%, 処理時間 = {baseline_2000[\"avg_time_ms\"]:.2f}ms\n",
    "  3段階最良:   Recall@10 = {best_cascade[\"recall@10\"]*100:.1f}%, 処理時間 = {best_cascade[\"avg_time_ms\"]:.2f}ms\n",
    "  \n",
    "  ※ 2段階検索は全件（40万件）のハミング距離を計算\n",
    "  ※ 3段階カスケードはStep1で候補を絞ってからハミング距離を計算\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": "---\n\n## 10. 実験評価まとめ\n\n### 実験目的\nOverlap(8/4)をベースに、3段階カスケード枝刈り方式を検証し、DB負荷低減と精度のバランスを探る。\n\n### 3段階枝刈りフロー\n\n```\n全データ (400,000件)\n    ↓ Step 1: Overlapセグメント一致 → 6.4万件（84%削減）\n候補 (step1_limit件)\n    ↓ Step 2: ハミング距離ソート\n候補 (step2_limit件)\n    ↓ Step 3: コサイン類似度\nTop-K 結果\n```\n\n### 検証した設定と結果\n\n| Overlap | S1 Limit | S2 Limit | R@10 | Step1 Raw | 削減率 | 処理時間 | 評価 |\n|---------|----------|----------|------|-----------|--------|----------|------|\n| **(8,4)** | 10000 | **2000** | **90.0%** | 63,764 | 97.5% | 23.5ms | **★推奨** |\n| (8,4) | 10000 | 1000 | 84.5% | 63,764 | 97.5% | 22.3ms | |\n| (8,4) | 5000 | 1000 | 84.5% | 63,764 | 98.8% | 21.3ms | |\n| (8,2) | 10000 | 1000 | 84.7% | 86,750 | 97.5% | 30.6ms | |\n| (16,4) | 5000 | 500 | 46.8% | 3,308 | 99.2% | 2.3ms | 精度不足 |\n\n### ベースライン（2段階検索）との比較\n\n| 手法 | R@10 | 全件計算 | 処理時間 | 備考 |\n|------|------|---------|----------|------|\n| **3段階(8,4)/10000/2000** | **90.0%** | **不要** | **23.5ms** | **★推奨** |\n| 2段階(2000) | 91.3% | 必要 | 36.2ms | ベースライン |\n| 2段階(1000) | 84.8% | 必要 | 35.5ms | |\n| 2段階(5000) | 96.0% | 必要 | 40.3ms | 高精度 |\n\n### 重要な発見\n\n1. **Step2のLimit（コサイン計算対象）が精度を決める**\n   - S2=500件: R@10 ≈ 74-75%（不足）\n   - S2=1000件: R@10 ≈ 84-85%（やや不足）\n   - S2=2000件: R@10 ≈ 90%（十分）\n\n2. **Overlap(8,4)の3段階カスケードが最適**\n   - Step1でセグメント一致: 40万件 → 6.4万件（84%削減）\n   - Step1でハミング距離絞り: 6.4万件 → 1万件\n   - Step2でハミング距離絞り: 1万件 → 2000件\n   - Step3でコサイン計算: 2000件 → Top-K\n\n3. **Overlap(16,x)は枝刈りしすぎて精度低下**\n   - 削減率99%以上だが、R@10は40%台\n   - 候補数が少なすぎて良い結果を逃す\n\n### シナリオ別推奨設定\n\n| シナリオ | Overlap | S1 Limit | S2 Limit | R@10 | 処理時間 |\n|---------|---------|----------|----------|------|----------|\n| **精度重視** | (8,4) | 10000 | 2000 | 90.0% | 23.5ms |\n| **バランス** | (8,4) | 5000 | 1000 | 84.5% | 21.3ms |\n| **高速重視** | (8,4) | 5000 | 500 | 74.4% | 20.5ms |\n\n### 結論\n\n1. **3段階カスケード方式は有効**\n   - 全件ハミング距離計算（40万件）を回避\n   - 処理時間35%短縮（36ms → 23ms）\n\n2. **Overlap(8,4) + S1=10000 + S2=2000が最適**\n   - R@10 = 90.0%（2段階91.3%との差は1.3pt）\n   - 処理時間23.5ms（2段階より35%高速）\n   - Step1で97.5%削減してからハミング距離計算\n\n3. **精度とコストのトレードオフ**\n   - S2を増やせば精度向上（S2=2000で90%達成）\n   - S2を減らせば高速化（S2=500で20ms）\n   - 用途に応じて調整可能\n\n### DBへの適用を考えた場合\n\n| 処理 | 3段階カスケード | 2段階検索 |\n|------|----------------|-----------|\n| Step1: インデックス引き | O(1) × 31セグメント | - |\n| Step1: ハミング距離計算 | 6.4万件 | **40万件** |\n| Step2: ハミング距離計算 | 1万件 | - |\n| Step3: ベクトル読み込み | **2000件** | **2000件** |\n| Step3: コサイン計算 | 2000件 | 2000件 |\n\n**結論: 3段階カスケードはハミング距離計算を6分の1に削減し、DBからのベクトル読み込みも同等に抑えられる。**\n\n### 次のステップ\n\n- DuckDBでのセグメントインデックス構築と検索の実装\n- 実際の外部クエリでの評価\n- インデックスサイズと構築時間の計測"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsh-cascade-poc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}