{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 84. 総合比較と推奨\n",
    "\n",
    "## 目的\n",
    "- 実験80-83の結果を統合し、全パイプラインを統一基準で比較\n",
    "- Pareto最適フロンティア（Recall vs 削減率）を特定\n",
    "\n",
    "## 比較パイプライン\n",
    "| ID | パイプライン | 説明 |\n",
    "|----|-------------|------|\n",
    "| A | ITQ Baseline | ITQ → Hamming top-K → Cosine |\n",
    "| B | ITQ + Pivot | ITQ → Pivot → Hamming → Cosine |\n",
    "| C | ITQ + Band | ITQ → Band filter → Hamming → Cosine |\n",
    "| D | ITQ + Band + Pivot | ITQ → Band → Pivot → Hamming → Cosine |\n",
    "| E | ITQ + Confidence probe | ITQ → Confidence bands → Hamming → Cosine |\n",
    "| F | ITQ + Confidence + Pivot | ITQ → Confidence bands → Pivot → Hamming → Cosine |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:02:05.753806Z",
     "iopub.status.busy": "2026-02-08T08:02:05.753636Z",
     "iopub.status.idle": "2026-02-08T08:02:06.669753Z",
     "shell.execute_reply": "2026-02-08T08:02:06.669234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: N_QUERIES=100, TOP_K=10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "from itq_lsh import ITQLSH, hamming_distance, hamming_distance_batch\n",
    "from dflsh import build_band_index, band_filter, confidence_multiprobe\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "np.random.seed(42)\n",
    "\n",
    "N_QUERIES = 100\n",
    "TOP_K = 10\n",
    "print(f'Configuration: N_QUERIES={N_QUERIES}, TOP_K={TOP_K}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:02:06.695890Z",
     "iopub.status.busy": "2026-02-08T08:02:06.695635Z",
     "iopub.status.idle": "2026-02-08T08:02:06.751995Z",
     "shell.execute_reply": "2026-02-08T08:02:06.751228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN: emb=(10000, 768), hash=(10000, 128), pivots=(8, 128)\n",
      "JA: emb=(10000, 768), hash=(10000, 128), pivots=(8, 128)\n",
      "MiniLM: emb=(10000, 384), hash=(10000, 128), pivots=(8, 128)\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "\n",
    "# English E5-base\n",
    "datasets['EN'] = {\n",
    "    'embeddings': np.load(DATA_DIR / '10k_e5_base_en_embeddings.npy'),\n",
    "    'hashes': np.load(DATA_DIR / '10k_e5_base_en_hashes_128bits.npy'),\n",
    "    'pivot_dist': np.load(DATA_DIR / '10k_e5_base_en_pivot_distances.npy'),\n",
    "    'pivots': np.load(DATA_DIR / 'pivots_8_e5_base_en.npy'),\n",
    "    'itq_model': ITQLSH.load(str(DATA_DIR / 'itq_e5_base_128bits.pkl')),\n",
    "}\n",
    "\n",
    "# Japanese E5-base\n",
    "datasets['JA'] = {\n",
    "    'embeddings': np.load(DATA_DIR / '10k_e5_base_ja_embeddings.npy'),\n",
    "    'hashes': np.load(DATA_DIR / '10k_e5_base_ja_hashes_128bits.npy'),\n",
    "    'pivot_dist': np.load(DATA_DIR / '10k_e5_base_ja_pivot_distances.npy'),\n",
    "    'pivots': np.load(DATA_DIR / 'pivots_8_e5_base_ja.npy'),\n",
    "    'itq_model': ITQLSH.load(str(DATA_DIR / 'itq_e5_base_128bits.pkl')),\n",
    "}\n",
    "\n",
    "# MiniLM\n",
    "datasets['MiniLM'] = {\n",
    "    'embeddings': np.load(DATA_DIR / '10k_minilm_embeddings.npy'),\n",
    "    'hashes': np.load(DATA_DIR / '10k_minilm_hashes_128bits.npy'),\n",
    "    'pivot_dist': np.load(DATA_DIR / '10k_minilm_pivot_distances.npy'),\n",
    "    'pivots': np.load(DATA_DIR / 'pivots_8_minilm.npy'),\n",
    "    'itq_model': ITQLSH.load(str(DATA_DIR / 'itq_minilm_128bits.pkl')),\n",
    "}\n",
    "\n",
    "for name, d in datasets.items():\n",
    "    print(f'{name}: emb={d[\"embeddings\"].shape}, hash={d[\"hashes\"].shape}, '\n",
    "          f'pivots={d[\"pivots\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 統一評価関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:02:06.753535Z",
     "iopub.status.busy": "2026-02-08T08:02:06.753369Z",
     "iopub.status.idle": "2026-02-08T08:02:06.759825Z",
     "shell.execute_reply": "2026-02-08T08:02:06.759229Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ground_truth(embeddings, qi, top_k=10):\n",
    "    cos_sims = cosine_similarity(embeddings[qi:qi+1], embeddings)[0]\n",
    "    cos_sims[qi] = -1\n",
    "    return set(np.argsort(cos_sims)[-top_k:])\n",
    "\n",
    "\n",
    "def evaluate_pipeline_unified(\n",
    "    embeddings, hashes, pivot_distances, pivots, itq_model,\n",
    "    pipeline_id, pipeline_name,\n",
    "    use_band=False, band_width=8, min_band_matches=1,\n",
    "    use_pivot=False, pivot_threshold=20,\n",
    "    use_confidence=False, max_probes=0,\n",
    "    candidate_limit=500\n",
    "):\n",
    "    \"\"\"統一パイプライン評価関数\"\"\"\n",
    "    rng = np.random.default_rng(42)\n",
    "    query_indices = rng.choice(len(embeddings), N_QUERIES, replace=False)\n",
    "    \n",
    "    bi = build_band_index(hashes, band_width) if (use_band or use_confidence) else None\n",
    "    all_projections = None\n",
    "    if use_confidence:\n",
    "        _, all_projections = itq_model.transform_with_confidence(embeddings)\n",
    "    \n",
    "    filter_recalls = []\n",
    "    final_recalls = []\n",
    "    filter_counts = []\n",
    "    total_times = []\n",
    "    \n",
    "    for qi in query_indices:\n",
    "        gt = get_ground_truth(embeddings, qi, TOP_K)\n",
    "        query_hash = hashes[qi]\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        # Stage 1: Candidate selection\n",
    "        if use_confidence:\n",
    "            query_proj = all_projections[qi]\n",
    "            cands = confidence_multiprobe(\n",
    "                query_hash, query_proj, bi, band_width,\n",
    "                max_probes=max_probes, order='confidence'\n",
    "            )\n",
    "            cands = cands[cands != qi]\n",
    "        elif use_band:\n",
    "            cands = band_filter(query_hash, bi, band_width, min_matches=min_band_matches)\n",
    "            cands = cands[cands != qi]\n",
    "        else:\n",
    "            cands = np.arange(len(embeddings))\n",
    "            cands = cands[cands != qi]\n",
    "        \n",
    "        # Stage 2: Pivot filter\n",
    "        if use_pivot and len(cands) > 0:\n",
    "            query_pivot_dists = np.array([\n",
    "                hamming_distance(query_hash, p) for p in pivots\n",
    "            ])\n",
    "            cand_pivot_dists = pivot_distances[cands]\n",
    "            mask = np.ones(len(cands), dtype=bool)\n",
    "            for i in range(len(pivots)):\n",
    "                lower = query_pivot_dists[i] - pivot_threshold\n",
    "                upper = query_pivot_dists[i] + pivot_threshold\n",
    "                mask &= (cand_pivot_dists[:, i] >= lower) & (cand_pivot_dists[:, i] <= upper)\n",
    "            cands = cands[mask]\n",
    "        \n",
    "        filter_counts.append(len(cands))\n",
    "        filter_recalls.append(len(gt & set(cands)) / TOP_K)\n",
    "        \n",
    "        # Stage 3: Hamming sort + Cosine rerank\n",
    "        if len(cands) > 0:\n",
    "            h_dists = hamming_distance_batch(query_hash, hashes[cands])\n",
    "            top_idx = np.argsort(h_dists)[:candidate_limit]\n",
    "            final_cands = cands[top_idx]\n",
    "            \n",
    "            cand_cos = cosine_similarity(embeddings[qi:qi+1], embeddings[final_cands])[0]\n",
    "            top_in_cand = final_cands[np.argsort(cand_cos)[-TOP_K:]]\n",
    "            final_recalls.append(len(gt & set(top_in_cand)) / TOP_K)\n",
    "        else:\n",
    "            final_recalls.append(0.0)\n",
    "        \n",
    "        total_times.append(time.time() - start)\n",
    "    \n",
    "    return {\n",
    "        'id': pipeline_id,\n",
    "        'name': pipeline_name,\n",
    "        'filter_candidates': np.mean(filter_counts),\n",
    "        'filter_candidates_std': np.std(filter_counts),\n",
    "        'reduction': 1 - np.mean(filter_counts) / len(embeddings),\n",
    "        'filter_recall': np.mean(filter_recalls),\n",
    "        'recall_at_k': np.mean(final_recalls),\n",
    "        'time_ms': np.mean(total_times) * 1000,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 全パイプライン評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:02:06.761192Z",
     "iopub.status.busy": "2026-02-08T08:02:06.761059Z",
     "iopub.status.idle": "2026-02-08T08:02:06.766428Z",
     "shell.execute_reply": "2026-02-08T08:02:06.765919Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_all_pipelines(data, dataset_name, candidate_limit=500):\n",
    "    \"\"\"全パイプラインを評価\"\"\"\n",
    "    emb = data['embeddings']\n",
    "    hashes = data['hashes']\n",
    "    pd = data['pivot_dist']\n",
    "    pivots = data['pivots']\n",
    "    itq_model = data['itq_model']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # A: ITQ Baseline (no filter)\n",
    "    results.append(evaluate_pipeline_unified(\n",
    "        emb, hashes, pd, pivots, itq_model,\n",
    "        'A', 'ITQ Baseline',\n",
    "        candidate_limit=candidate_limit\n",
    "    ))\n",
    "    \n",
    "    # B: ITQ + Pivot (threshold=20)\n",
    "    results.append(evaluate_pipeline_unified(\n",
    "        emb, hashes, pd, pivots, itq_model,\n",
    "        'B', 'ITQ+Pivot(t=20)',\n",
    "        use_pivot=True, pivot_threshold=20,\n",
    "        candidate_limit=candidate_limit\n",
    "    ))\n",
    "    \n",
    "    # B2: ITQ + Pivot (threshold=25)\n",
    "    results.append(evaluate_pipeline_unified(\n",
    "        emb, hashes, pd, pivots, itq_model,\n",
    "        'B2', 'ITQ+Pivot(t=25)',\n",
    "        use_pivot=True, pivot_threshold=25,\n",
    "        candidate_limit=candidate_limit\n",
    "    ))\n",
    "    \n",
    "    # C: ITQ + Band (bw=8)\n",
    "    results.append(evaluate_pipeline_unified(\n",
    "        emb, hashes, pd, pivots, itq_model,\n",
    "        'C', 'ITQ+Band(bw=8)',\n",
    "        use_band=True, band_width=8,\n",
    "        candidate_limit=candidate_limit\n",
    "    ))\n",
    "    \n",
    "    # D: ITQ + Band + Pivot (bw=8, pt=20)\n",
    "    results.append(evaluate_pipeline_unified(\n",
    "        emb, hashes, pd, pivots, itq_model,\n",
    "        'D', 'ITQ+Band(8)+Pivot(20)',\n",
    "        use_band=True, band_width=8,\n",
    "        use_pivot=True, pivot_threshold=20,\n",
    "        candidate_limit=candidate_limit\n",
    "    ))\n",
    "    \n",
    "    # D2: ITQ + Band + Pivot (bw=8, pt=25)\n",
    "    results.append(evaluate_pipeline_unified(\n",
    "        emb, hashes, pd, pivots, itq_model,\n",
    "        'D2', 'ITQ+Band(8)+Pivot(25)',\n",
    "        use_band=True, band_width=8,\n",
    "        use_pivot=True, pivot_threshold=25,\n",
    "        candidate_limit=candidate_limit\n",
    "    ))\n",
    "    \n",
    "    # E: ITQ + Confidence probe (bw=8, 8 probes)\n",
    "    results.append(evaluate_pipeline_unified(\n",
    "        emb, hashes, pd, pivots, itq_model,\n",
    "        'E', 'ITQ+Conf(bw=8,p=8)',\n",
    "        use_confidence=True, band_width=8, max_probes=8,\n",
    "        candidate_limit=candidate_limit\n",
    "    ))\n",
    "    \n",
    "    # E2: ITQ + Confidence probe (bw=8, 16 probes)\n",
    "    results.append(evaluate_pipeline_unified(\n",
    "        emb, hashes, pd, pivots, itq_model,\n",
    "        'E2', 'ITQ+Conf(bw=8,p=16)',\n",
    "        use_confidence=True, band_width=8, max_probes=16,\n",
    "        candidate_limit=candidate_limit\n",
    "    ))\n",
    "    \n",
    "    # F: ITQ + Confidence + Pivot (bw=8, 8 probes, pt=20)\n",
    "    results.append(evaluate_pipeline_unified(\n",
    "        emb, hashes, pd, pivots, itq_model,\n",
    "        'F', 'ITQ+Conf(8,8)+Pvt(20)',\n",
    "        use_confidence=True, band_width=8, max_probes=8,\n",
    "        use_pivot=True, pivot_threshold=20,\n",
    "        candidate_limit=candidate_limit\n",
    "    ))\n",
    "    \n",
    "    # F2: ITQ + Confidence + Pivot (bw=8, 16 probes, pt=25)\n",
    "    results.append(evaluate_pipeline_unified(\n",
    "        emb, hashes, pd, pivots, itq_model,\n",
    "        'F2', 'ITQ+Conf(8,16)+Pvt(25)',\n",
    "        use_confidence=True, band_width=8, max_probes=16,\n",
    "        use_pivot=True, pivot_threshold=25,\n",
    "        candidate_limit=candidate_limit\n",
    "    ))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_results_table(results, dataset_name, candidate_limit):\n",
    "    \"\"\"結果テーブルを表示\"\"\"\n",
    "    print(f'\\n{dataset_name} (candidate_limit={candidate_limit})')\n",
    "    print(f'{\"ID\":<4} {\"Pipeline\":<25} {\"Cands\":>8} {\"Reduction\":>10} '\n",
    "          f'{\"FiltRcl\":>8} {\"R@10\":>8} {\"Time(ms)\":>10}')\n",
    "    print('-' * 80)\n",
    "    for r in results:\n",
    "        print(f'{r[\"id\"]:<4} {r[\"name\"]:<25} {r[\"filter_candidates\"]:>7.0f} '\n",
    "              f'{r[\"reduction\"]*100:>9.1f}% '\n",
    "              f'{r[\"filter_recall\"]*100:>7.1f}% '\n",
    "              f'{r[\"recall_at_k\"]*100:>7.1f}% '\n",
    "              f'{r[\"time_ms\"]:>9.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:02:06.767675Z",
     "iopub.status.busy": "2026-02-08T08:02:06.767552Z",
     "iopub.status.idle": "2026-02-08T08:03:36.155189Z",
     "shell.execute_reply": "2026-02-08T08:03:36.154617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Full Pipeline Comparison\n",
      "================================================================================\n",
      "\n",
      "Evaluating EN...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EN E5-base (candidate_limit=500)\n",
      "ID   Pipeline                     Cands  Reduction  FiltRcl     R@10   Time(ms)\n",
      "--------------------------------------------------------------------------------\n",
      "A    ITQ Baseline                 9999       0.0%   100.0%    84.0%      3.28\n",
      "B    ITQ+Pivot(t=20)              9055       9.4%    99.2%    84.2%      3.55\n",
      "B2   ITQ+Pivot(t=25)              9825       1.7%    99.9%    84.0%      3.67\n",
      "C    ITQ+Band(bw=8)               2181      78.2%    68.9%    66.0%      2.69\n",
      "D    ITQ+Band(8)+Pivot(20)        2039      79.6%    68.4%    66.1%      2.75\n",
      "D2   ITQ+Band(8)+Pivot(25)        2158      78.4%    68.8%    66.0%      2.84\n",
      "E    ITQ+Conf(bw=8,p=8)           2793      72.1%    75.6%    71.4%      3.07\n",
      "E2   ITQ+Conf(bw=8,p=16)          3757      62.4%    85.1%    78.0%      3.60\n",
      "F    ITQ+Conf(8,8)+Pvt(20)        2601      74.0%    75.1%    71.0%      3.27\n",
      "F2   ITQ+Conf(8,16)+Pvt(25)       3713      62.9%    85.0%    77.8%      3.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EN E5-base (candidate_limit=100)\n",
      "ID   Pipeline                     Cands  Reduction  FiltRcl     R@10   Time(ms)\n",
      "--------------------------------------------------------------------------------\n",
      "A    ITQ Baseline                 9999       0.0%   100.0%    61.0%      2.79\n",
      "B    ITQ+Pivot(t=20)              9055       9.4%    99.2%    61.4%      3.05\n",
      "B2   ITQ+Pivot(t=25)              9825       1.7%    99.9%    60.6%      3.17\n",
      "C    ITQ+Band(bw=8)               2181      78.2%    68.9%    53.1%      1.88\n",
      "D    ITQ+Band(8)+Pivot(20)        2039      79.6%    68.4%    53.6%      2.07\n",
      "D2   ITQ+Band(8)+Pivot(25)        2158      78.4%    68.8%    53.4%      2.10\n",
      "E    ITQ+Conf(bw=8,p=8)           2793      72.1%    75.6%    56.4%      2.40\n",
      "E2   ITQ+Conf(bw=8,p=16)          3757      62.4%    85.1%    59.7%      2.84\n",
      "F    ITQ+Conf(8,8)+Pvt(20)        2601      74.0%    75.1%    56.4%      2.58\n",
      "F2   ITQ+Conf(8,16)+Pvt(25)       3713      62.9%    85.0%    59.6%      3.14\n",
      "\n",
      "Evaluating JA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JA E5-base (candidate_limit=500)\n",
      "ID   Pipeline                     Cands  Reduction  FiltRcl     R@10   Time(ms)\n",
      "--------------------------------------------------------------------------------\n",
      "A    ITQ Baseline                 9999       0.0%   100.0%    98.1%      3.47\n",
      "B    ITQ+Pivot(t=20)              6956      30.4%    98.1%    96.7%      3.43\n",
      "B2   ITQ+Pivot(t=25)              8738      12.6%    99.9%    98.0%      3.69\n",
      "C    ITQ+Band(bw=8)                694      93.1%    63.9%    63.9%      2.06\n",
      "D    ITQ+Band(8)+Pivot(20)         560      94.4%    63.0%    63.0%      2.04\n",
      "D2   ITQ+Band(8)+Pivot(25)         646      93.5%    63.8%    63.8%      2.17\n",
      "E    ITQ+Conf(bw=8,p=8)           1002      90.0%    72.4%    72.4%      2.39\n",
      "E2   ITQ+Conf(bw=8,p=16)          1318      86.8%    82.9%    82.7%      2.59\n",
      "F    ITQ+Conf(8,8)+Pvt(20)         798      92.0%    71.5%    71.5%      2.46\n",
      "F2   ITQ+Conf(8,16)+Pvt(25)       1221      87.8%    82.8%    82.6%      2.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JA E5-base (candidate_limit=100)\n",
      "ID   Pipeline                     Cands  Reduction  FiltRcl     R@10   Time(ms)\n",
      "--------------------------------------------------------------------------------\n",
      "A    ITQ Baseline                 9999       0.0%   100.0%    83.5%      2.84\n",
      "B    ITQ+Pivot(t=20)              6956      30.4%    98.1%    81.8%      2.74\n",
      "B2   ITQ+Pivot(t=25)              8738      12.6%    99.9%    83.1%      3.02\n",
      "C    ITQ+Band(bw=8)                694      93.1%    63.9%    61.9%      1.29\n",
      "D    ITQ+Band(8)+Pivot(20)         560      94.4%    63.0%    61.1%      1.39\n",
      "D2   ITQ+Band(8)+Pivot(25)         646      93.5%    63.8%    61.7%      1.46\n",
      "E    ITQ+Conf(bw=8,p=8)           1002      90.0%    72.4%    69.0%      1.69\n",
      "E2   ITQ+Conf(bw=8,p=16)          1318      86.8%    82.9%    77.4%      1.90\n",
      "F    ITQ+Conf(8,8)+Pvt(20)         798      92.0%    71.5%    68.7%      1.77\n",
      "F2   ITQ+Conf(8,16)+Pvt(25)       1221      87.8%    82.8%    76.9%      2.03\n",
      "\n",
      "Evaluating MiniLM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MiniLM (candidate_limit=500)\n",
      "ID   Pipeline                     Cands  Reduction  FiltRcl     R@10   Time(ms)\n",
      "--------------------------------------------------------------------------------\n",
      "A    ITQ Baseline                 9999       0.0%   100.0%    98.3%      3.36\n",
      "B    ITQ+Pivot(t=20)              8025      19.8%    96.7%    95.2%      3.49\n",
      "B2   ITQ+Pivot(t=25)              9360       6.4%    98.8%    97.1%      3.65\n",
      "C    ITQ+Band(bw=8)                654      93.5%    50.9%    50.9%      1.90\n",
      "D    ITQ+Band(8)+Pivot(20)         557      94.4%    49.2%    49.2%      1.96\n",
      "D2   ITQ+Band(8)+Pivot(25)         624      93.8%    50.1%    50.1%      2.00\n",
      "E    ITQ+Conf(bw=8,p=8)            955      90.5%    59.5%    59.5%      2.27\n",
      "E2   ITQ+Conf(bw=8,p=16)          1250      87.5%    71.4%    71.4%      2.48\n",
      "F    ITQ+Conf(8,8)+Pvt(20)         810      91.9%    57.5%    57.5%      2.35\n",
      "F2   ITQ+Conf(8,16)+Pvt(25)       1192      88.1%    70.3%    70.3%      2.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MiniLM (candidate_limit=100)\n",
      "ID   Pipeline                     Cands  Reduction  FiltRcl     R@10   Time(ms)\n",
      "--------------------------------------------------------------------------------\n",
      "A    ITQ Baseline                 9999       0.0%   100.0%    87.7%      2.81\n",
      "B    ITQ+Pivot(t=20)              8025      19.8%    96.7%    85.7%      2.88\n",
      "B2   ITQ+Pivot(t=25)              9360       6.4%    98.8%    87.1%      3.10\n",
      "C    ITQ+Band(bw=8)                654      93.5%    50.9%    50.5%      1.25\n",
      "D    ITQ+Band(8)+Pivot(20)         557      94.4%    49.2%    48.8%      1.35\n",
      "D2   ITQ+Band(8)+Pivot(25)         624      93.8%    50.1%    49.7%      1.38\n",
      "E    ITQ+Conf(bw=8,p=8)            955      90.5%    59.5%    58.3%      1.65\n",
      "E2   ITQ+Conf(bw=8,p=16)          1250      87.5%    71.4%    68.9%      1.92\n",
      "F    ITQ+Conf(8,8)+Pvt(20)         810      91.9%    57.5%    56.5%      1.74\n",
      "F2   ITQ+Conf(8,16)+Pvt(25)       1192      88.1%    70.3%    67.8%      2.01\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('Full Pipeline Comparison')\n",
    "print('='*80)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name in ['EN', 'JA', 'MiniLM']:\n",
    "    print(f'\\nEvaluating {dataset_name}...')\n",
    "    \n",
    "    # candidate_limit=500\n",
    "    results_500 = run_all_pipelines(datasets[dataset_name], dataset_name, candidate_limit=500)\n",
    "    print_results_table(results_500, f'{dataset_name} E5-base' if dataset_name != 'MiniLM' else 'MiniLM', 500)\n",
    "    all_results[f'{dataset_name}_500'] = results_500\n",
    "    \n",
    "    # candidate_limit=100\n",
    "    results_100 = run_all_pipelines(datasets[dataset_name], dataset_name, candidate_limit=100)\n",
    "    print_results_table(results_100, f'{dataset_name} E5-base' if dataset_name != 'MiniLM' else 'MiniLM', 100)\n",
    "    all_results[f'{dataset_name}_100'] = results_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pareto最適フロンティア分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:03:36.156743Z",
     "iopub.status.busy": "2026-02-08T08:03:36.156475Z",
     "iopub.status.idle": "2026-02-08T08:03:36.162342Z",
     "shell.execute_reply": "2026-02-08T08:03:36.161458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Pareto Optimal Frontier Analysis\n",
      "================================================================================\n",
      "\n",
      "--- EN (candidate_limit=500) ---\n",
      "Pareto optimal pipelines (6/10):\n",
      "  B: ITQ+Pivot(t=20)           R@10=84.2%, Cands=9055, Time=3.55ms\n",
      "  E2: ITQ+Conf(bw=8,p=16)       R@10=78.0%, Cands=3757, Time=3.60ms\n",
      "  F2: ITQ+Conf(8,16)+Pvt(25)    R@10=77.8%, Cands=3713, Time=3.75ms\n",
      "  E: ITQ+Conf(bw=8,p=8)        R@10=71.4%, Cands=2793, Time=3.07ms\n",
      "  F: ITQ+Conf(8,8)+Pvt(20)     R@10=71.0%, Cands=2601, Time=3.27ms\n",
      "  D: ITQ+Band(8)+Pivot(20)     R@10=66.1%, Cands=2039, Time=2.75ms\n",
      "\n",
      "--- JA (candidate_limit=500) ---\n",
      "Pareto optimal pipelines (10/10):\n",
      "  A: ITQ Baseline              R@10=98.1%, Cands=9999, Time=3.47ms\n",
      "  B2: ITQ+Pivot(t=25)           R@10=98.0%, Cands=8738, Time=3.69ms\n",
      "  B: ITQ+Pivot(t=20)           R@10=96.7%, Cands=6956, Time=3.43ms\n",
      "  E2: ITQ+Conf(bw=8,p=16)       R@10=82.7%, Cands=1318, Time=2.59ms\n",
      "  F2: ITQ+Conf(8,16)+Pvt(25)    R@10=82.6%, Cands=1221, Time=2.72ms\n",
      "  E: ITQ+Conf(bw=8,p=8)        R@10=72.4%, Cands=1002, Time=2.39ms\n",
      "  F: ITQ+Conf(8,8)+Pvt(20)     R@10=71.5%, Cands=798, Time=2.46ms\n",
      "  C: ITQ+Band(bw=8)            R@10=63.9%, Cands=694, Time=2.06ms\n",
      "  D2: ITQ+Band(8)+Pivot(25)     R@10=63.8%, Cands=646, Time=2.17ms\n",
      "  D: ITQ+Band(8)+Pivot(20)     R@10=63.0%, Cands=560, Time=2.04ms\n",
      "\n",
      "--- MiniLM (candidate_limit=500) ---\n",
      "Pareto optimal pipelines (10/10):\n",
      "  A: ITQ Baseline              R@10=98.3%, Cands=9999, Time=3.36ms\n",
      "  B2: ITQ+Pivot(t=25)           R@10=97.1%, Cands=9360, Time=3.65ms\n",
      "  B: ITQ+Pivot(t=20)           R@10=95.2%, Cands=8025, Time=3.49ms\n",
      "  E2: ITQ+Conf(bw=8,p=16)       R@10=71.4%, Cands=1250, Time=2.48ms\n",
      "  F2: ITQ+Conf(8,16)+Pvt(25)    R@10=70.3%, Cands=1192, Time=2.61ms\n",
      "  E: ITQ+Conf(bw=8,p=8)        R@10=59.5%, Cands=955, Time=2.27ms\n",
      "  F: ITQ+Conf(8,8)+Pvt(20)     R@10=57.5%, Cands=810, Time=2.35ms\n",
      "  C: ITQ+Band(bw=8)            R@10=50.9%, Cands=654, Time=1.90ms\n",
      "  D2: ITQ+Band(8)+Pivot(25)     R@10=50.1%, Cands=624, Time=2.00ms\n",
      "  D: ITQ+Band(8)+Pivot(20)     R@10=49.2%, Cands=557, Time=1.96ms\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('Pareto Optimal Frontier Analysis')\n",
    "print('='*80)\n",
    "\n",
    "def find_pareto(results):\n",
    "    \"\"\"Pareto最適解を特定（Recall最大化 & 候補数最小化）\"\"\"\n",
    "    pareto = []\n",
    "    for r in results:\n",
    "        dominated = False\n",
    "        for other in results:\n",
    "            if other is r:\n",
    "                continue\n",
    "            # otherがrを支配: Recall同等以上 かつ 候補数同等以下 かつ 少なくとも1つで厳密に良い\n",
    "            if (other['recall_at_k'] >= r['recall_at_k'] and \n",
    "                other['filter_candidates'] <= r['filter_candidates'] and\n",
    "                (other['recall_at_k'] > r['recall_at_k'] or \n",
    "                 other['filter_candidates'] < r['filter_candidates'])):\n",
    "                dominated = True\n",
    "                break\n",
    "        if not dominated:\n",
    "            pareto.append(r)\n",
    "    return sorted(pareto, key=lambda x: x['recall_at_k'], reverse=True)\n",
    "\n",
    "\n",
    "for key in ['EN_500', 'JA_500', 'MiniLM_500']:\n",
    "    results = all_results[key]\n",
    "    pareto = find_pareto(results)\n",
    "    \n",
    "    dataset_label = key.split('_')[0]\n",
    "    print(f'\\n--- {dataset_label} (candidate_limit=500) ---')\n",
    "    print(f'Pareto optimal pipelines ({len(pareto)}/{len(results)}):')\n",
    "    for r in pareto:\n",
    "        print(f'  {r[\"id\"]}: {r[\"name\"]:<25} R@10={r[\"recall_at_k\"]*100:.1f}%, '\n",
    "              f'Cands={r[\"filter_candidates\"]:.0f}, Time={r[\"time_ms\"]:.2f}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 英語 vs 日本語の比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:03:36.163739Z",
     "iopub.status.busy": "2026-02-08T08:03:36.163586Z",
     "iopub.status.idle": "2026-02-08T08:03:36.167953Z",
     "shell.execute_reply": "2026-02-08T08:03:36.167388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "English vs Japanese Comparison\n",
      "================================================================================\n",
      "\n",
      "Pipeline                  |    --- English ---     |    --- Japanese ---    |      差\n",
      "                          |     R@10      Cands |     R@10      Cands |  ΔR@10\n",
      "-------------------------------------------------------------------------------------\n",
      "ITQ Baseline              |    84.0%      9999 |    98.1%      9999 | +14.1%\n",
      "ITQ+Pivot(t=20)           |    84.2%      9055 |    96.7%      6956 | +12.5%\n",
      "ITQ+Pivot(t=25)           |    84.0%      9825 |    98.0%      8738 | +14.0%\n",
      "ITQ+Band(bw=8)            |    66.0%      2181 |    63.9%       694 |  -2.1%\n",
      "ITQ+Band(8)+Pivot(20)     |    66.1%      2039 |    63.0%       560 |  -3.1%\n",
      "ITQ+Band(8)+Pivot(25)     |    66.0%      2158 |    63.8%       646 |  -2.2%\n",
      "ITQ+Conf(bw=8,p=8)        |    71.4%      2793 |    72.4%      1002 |  +1.0%\n",
      "ITQ+Conf(bw=8,p=16)       |    78.0%      3757 |    82.7%      1318 |  +4.7%\n",
      "ITQ+Conf(8,8)+Pvt(20)     |    71.0%      2601 |    71.5%       798 |  +0.5%\n",
      "ITQ+Conf(8,16)+Pvt(25)    |    77.8%      3713 |    82.6%      1221 |  +4.8%\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('English vs Japanese Comparison')\n",
    "print('='*80)\n",
    "\n",
    "en_results = all_results['EN_500']\n",
    "ja_results = all_results['JA_500']\n",
    "\n",
    "print(f'\\n{\"Pipeline\":<25} | {\"--- English ---\":^22} | {\"--- Japanese ---\":^22} | {\"差\":>6}')\n",
    "print(f'{\"\":<25} | {\"R@10\":>8} {\"Cands\":>10} | {\"R@10\":>8} {\"Cands\":>10} | {\"ΔR@10\":>6}')\n",
    "print('-' * 85)\n",
    "for en, ja in zip(en_results, ja_results):\n",
    "    delta = ja['recall_at_k'] * 100 - en['recall_at_k'] * 100\n",
    "    print(f'{en[\"name\"]:<25} | '\n",
    "          f'{en[\"recall_at_k\"]*100:>7.1f}% {en[\"filter_candidates\"]:>9.0f} | '\n",
    "          f'{ja[\"recall_at_k\"]*100:>7.1f}% {ja[\"filter_candidates\"]:>9.0f} | '\n",
    "          f'{delta:>+5.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 推奨パイプライン分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:03:36.170159Z",
     "iopub.status.busy": "2026-02-08T08:03:36.169433Z",
     "iopub.status.idle": "2026-02-08T08:03:36.176656Z",
     "shell.execute_reply": "2026-02-08T08:03:36.175757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Recommended Pipeline Analysis\n",
      "================================================================================\n",
      "\n",
      "--- EN ---\n",
      "Top-3 by Recall@10:\n",
      "  1. ITQ+Pivot(t=20)           R@10=84.2%, Cands=9055, Reduction=9.4%, Time=3.55ms\n",
      "  2. ITQ Baseline              R@10=84.0%, Cands=9999, Reduction=0.0%, Time=3.28ms\n",
      "  3. ITQ+Pivot(t=25)           R@10=84.0%, Cands=9825, Reduction=1.7%, Time=3.67ms\n",
      "  Best with >50% reduction: ITQ+Conf(bw=8,p=16) R@10=78.0%, Reduction=62.4%\n",
      "\n",
      "--- JA ---\n",
      "Top-3 by Recall@10:\n",
      "  1. ITQ Baseline              R@10=98.1%, Cands=9999, Reduction=0.0%, Time=3.47ms\n",
      "  2. ITQ+Pivot(t=25)           R@10=98.0%, Cands=8738, Reduction=12.6%, Time=3.69ms\n",
      "  3. ITQ+Pivot(t=20)           R@10=96.7%, Cands=6956, Reduction=30.4%, Time=3.43ms\n",
      "  Best with >50% reduction: ITQ+Conf(bw=8,p=16) R@10=82.7%, Reduction=86.8%\n",
      "  Best with >90% reduction: ITQ+Conf(8,8)+Pvt(20) R@10=71.5%, Reduction=92.0%\n",
      "\n",
      "--- MiniLM ---\n",
      "Top-3 by Recall@10:\n",
      "  1. ITQ Baseline              R@10=98.3%, Cands=9999, Reduction=0.0%, Time=3.36ms\n",
      "  2. ITQ+Pivot(t=25)           R@10=97.1%, Cands=9360, Reduction=6.4%, Time=3.65ms\n",
      "  3. ITQ+Pivot(t=20)           R@10=95.2%, Cands=8025, Reduction=19.8%, Time=3.49ms\n",
      "  Best with >50% reduction: ITQ+Conf(bw=8,p=16) R@10=71.4%, Reduction=87.5%\n",
      "  Best with >90% reduction: ITQ+Conf(bw=8,p=8) R@10=59.5%, Reduction=90.5%\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('Recommended Pipeline Analysis')\n",
    "print('='*80)\n",
    "\n",
    "# 各データセットで最高Recall@10を達成するパイプラインを特定\n",
    "for key in ['EN_500', 'JA_500', 'MiniLM_500']:\n",
    "    results = all_results[key]\n",
    "    dataset_label = key.split('_')[0]\n",
    "    \n",
    "    # Recall@10でソート\n",
    "    sorted_results = sorted(results, key=lambda x: x['recall_at_k'], reverse=True)\n",
    "    \n",
    "    print(f'\\n--- {dataset_label} ---')\n",
    "    print(f'Top-3 by Recall@10:')\n",
    "    for i, r in enumerate(sorted_results[:3]):\n",
    "        print(f'  {i+1}. {r[\"name\"]:<25} R@10={r[\"recall_at_k\"]*100:.1f}%, '\n",
    "              f'Cands={r[\"filter_candidates\"]:.0f}, '\n",
    "              f'Reduction={r[\"reduction\"]*100:.1f}%, '\n",
    "              f'Time={r[\"time_ms\"]:.2f}ms')\n",
    "    \n",
    "    # 削減率50%以上でのベスト\n",
    "    filtered = [r for r in results if r['reduction'] > 0.5]\n",
    "    if filtered:\n",
    "        best_filtered = max(filtered, key=lambda x: x['recall_at_k'])\n",
    "        print(f'  Best with >50% reduction: {best_filtered[\"name\"]} '\n",
    "              f'R@10={best_filtered[\"recall_at_k\"]*100:.1f}%, '\n",
    "              f'Reduction={best_filtered[\"reduction\"]*100:.1f}%')\n",
    "    \n",
    "    # 削減率90%以上でのベスト\n",
    "    filtered90 = [r for r in results if r['reduction'] > 0.9]\n",
    "    if filtered90:\n",
    "        best_filtered90 = max(filtered90, key=lambda x: x['recall_at_k'])\n",
    "        print(f'  Best with >90% reduction: {best_filtered90[\"name\"]} '\n",
    "              f'R@10={best_filtered90[\"recall_at_k\"]*100:.1f}%, '\n",
    "              f'Reduction={best_filtered90[\"reduction\"]*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Filter Recall vs Recall@10の関係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:03:36.178221Z",
     "iopub.status.busy": "2026-02-08T08:03:36.178066Z",
     "iopub.status.idle": "2026-02-08T08:03:36.183412Z",
     "shell.execute_reply": "2026-02-08T08:03:36.183010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Filter Recall vs Recall@10 Analysis\n",
      "================================================================================\n",
      "\n",
      "Filter Recallが低い場合のR@10への影響:\n",
      "（Filter Recallは真のTop-10が候補に残る割合、R@10は最終精度）\n",
      "\n",
      "--- EN ---\n",
      "Pipeline                   FiltRcl     R@10      Gap    Cands\n",
      "------------------------------------------------------------\n",
      "ITQ Baseline                100.0%    84.0%   +16.0%    9999\n",
      "ITQ+Pivot(t=20)              99.2%    84.2%   +15.0%    9055\n",
      "ITQ+Pivot(t=25)              99.9%    84.0%   +15.9%    9825\n",
      "ITQ+Band(bw=8)               68.9%    66.0%    +2.9%    2181\n",
      "ITQ+Band(8)+Pivot(20)        68.4%    66.1%    +2.3%    2039\n",
      "ITQ+Band(8)+Pivot(25)        68.8%    66.0%    +2.8%    2158\n",
      "ITQ+Conf(bw=8,p=8)           75.6%    71.4%    +4.2%    2793\n",
      "ITQ+Conf(bw=8,p=16)          85.1%    78.0%    +7.1%    3757\n",
      "ITQ+Conf(8,8)+Pvt(20)        75.1%    71.0%    +4.1%    2601\n",
      "ITQ+Conf(8,16)+Pvt(25)       85.0%    77.8%    +7.2%    3713\n",
      "\n",
      "--- JA ---\n",
      "Pipeline                   FiltRcl     R@10      Gap    Cands\n",
      "------------------------------------------------------------\n",
      "ITQ Baseline                100.0%    98.1%    +1.9%    9999\n",
      "ITQ+Pivot(t=20)              98.1%    96.7%    +1.4%    6956\n",
      "ITQ+Pivot(t=25)              99.9%    98.0%    +1.9%    8738\n",
      "ITQ+Band(bw=8)               63.9%    63.9%    +0.0%     694\n",
      "ITQ+Band(8)+Pivot(20)        63.0%    63.0%    +0.0%     560\n",
      "ITQ+Band(8)+Pivot(25)        63.8%    63.8%    +0.0%     646\n",
      "ITQ+Conf(bw=8,p=8)           72.4%    72.4%    +0.0%    1002\n",
      "ITQ+Conf(bw=8,p=16)          82.9%    82.7%    +0.2%    1318\n",
      "ITQ+Conf(8,8)+Pvt(20)        71.5%    71.5%    +0.0%     798\n",
      "ITQ+Conf(8,16)+Pvt(25)       82.8%    82.6%    +0.2%    1221\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('Filter Recall vs Recall@10 Analysis')\n",
    "print('='*80)\n",
    "\n",
    "print('\\nFilter Recallが低い場合のR@10への影響:')\n",
    "print('（Filter Recallは真のTop-10が候補に残る割合、R@10は最終精度）')\n",
    "\n",
    "for key in ['EN_500', 'JA_500']:\n",
    "    results = all_results[key]\n",
    "    dataset_label = key.split('_')[0]\n",
    "    \n",
    "    print(f'\\n--- {dataset_label} ---')\n",
    "    print(f'{\"Pipeline\":<25} {\"FiltRcl\":>8} {\"R@10\":>8} {\"Gap\":>8} {\"Cands\":>8}')\n",
    "    print('-' * 60)\n",
    "    for r in results:\n",
    "        gap = r['filter_recall'] * 100 - r['recall_at_k'] * 100\n",
    "        print(f'{r[\"name\"]:<25} {r[\"filter_recall\"]*100:>7.1f}% '\n",
    "              f'{r[\"recall_at_k\"]*100:>7.1f}% {gap:>+7.1f}% '\n",
    "              f'{r[\"filter_candidates\"]:>7.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 総合サマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:03:36.185865Z",
     "iopub.status.busy": "2026-02-08T08:03:36.185246Z",
     "iopub.status.idle": "2026-02-08T08:03:36.192953Z",
     "shell.execute_reply": "2026-02-08T08:03:36.192120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DF-LSH Integration Experiment Series (80-84) Summary\n",
      "================================================================================\n",
      "\n",
      "【実験81: DF-LSH独立評価】\n",
      "- ITQ-LSHのバイナリコード品質がDF-LSH(PCA)を大幅に上回る\n",
      "  (Spearman: ITQ=-0.47 vs PCA=-0.23 / English)\n",
      "- ITQ回転行列の最適化が量子化品質に大きく寄与\n",
      "- DF-LSH独立では既存ITQ-LSHを覆す効果なし\n",
      "\n",
      "【実験82: Bloomフィルタ（バンドプリフィルタ）】\n",
      "- バンドフィルタ（bw=8）でITQハッシュの候補を高速絞り込み可能\n",
      "- Pivotと組み合わせることで2段フィルタリングが機能\n",
      "- ただし、バンド完全一致は厳しく、Recall低下のリスク\n",
      "\n",
      "【実験83: Confidence Multi-probe】\n",
      "- ITQ射影値の|Z|を確信度として利用したmulti-probe\n",
      "- confidence順 vs ランダム順でprobe効率を比較\n",
      "- 確信度の低いビットを優先フリップすることでRecall回復\n",
      "\n",
      "【実験84: 総合比較（本ノートブック）】\n",
      "\n",
      "  [EN]\n",
      "    Baseline (A):  R@10=84.0%\n",
      "    Best overall:  ITQ+Pivot(t=20) R@10=84.2%\n",
      "    Best efficient: ITQ+Conf(bw=8,p=16) R@10=78.0%, Reduction=62.4%\n",
      "\n",
      "  [JA]\n",
      "    Baseline (A):  R@10=98.1%\n",
      "    Best overall:  ITQ Baseline R@10=98.1%\n",
      "    Best efficient: ITQ+Conf(bw=8,p=16) R@10=82.7%, Reduction=86.8%\n",
      "\n",
      "  [MiniLM]\n",
      "    Baseline (A):  R@10=98.3%\n",
      "    Best overall:  ITQ Baseline R@10=98.3%\n",
      "    Best efficient: ITQ+Conf(bw=8,p=16) R@10=71.4%, Reduction=87.5%\n",
      "\n",
      "【結論】\n",
      "1. ITQ回転行列の最適化は量子化品質の核心であり、DF-LSHのPCA射影では代替不可\n",
      "2. バンドインデックスはITQハッシュ上でプリフィルタとして利用可能\n",
      "3. Confidence multi-probeにより、バンドフィルタのRecall低下を部分的に回復\n",
      "4. 現行のITQ+Pivotパイプラインが依然として最良のバランス\n",
      "5. バンドプリフィルタの追加は、大規模データ（100K+）で計算量削減の効果が期待\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('DF-LSH Integration Experiment Series (80-84) Summary')\n",
    "print('='*80)\n",
    "\n",
    "print('\\n【実験81: DF-LSH独立評価】')\n",
    "print('- ITQ-LSHのバイナリコード品質がDF-LSH(PCA)を大幅に上回る')\n",
    "print('  (Spearman: ITQ=-0.47 vs PCA=-0.23 / English)')\n",
    "print('- ITQ回転行列の最適化が量子化品質に大きく寄与')\n",
    "print('- DF-LSH独立では既存ITQ-LSHを覆す効果なし')\n",
    "\n",
    "print('\\n【実験82: Bloomフィルタ（バンドプリフィルタ）】')\n",
    "print('- バンドフィルタ（bw=8）でITQハッシュの候補を高速絞り込み可能')\n",
    "print('- Pivotと組み合わせることで2段フィルタリングが機能')\n",
    "print('- ただし、バンド完全一致は厳しく、Recall低下のリスク')\n",
    "\n",
    "print('\\n【実験83: Confidence Multi-probe】')\n",
    "print('- ITQ射影値の|Z|を確信度として利用したmulti-probe')\n",
    "print('- confidence順 vs ランダム順でprobe効率を比較')\n",
    "print('- 確信度の低いビットを優先フリップすることでRecall回復')\n",
    "\n",
    "print('\\n【実験84: 総合比較（本ノートブック）】')\n",
    "\n",
    "# 各データセットの推奨を出力\n",
    "for key in ['EN_500', 'JA_500', 'MiniLM_500']:\n",
    "    results = all_results[key]\n",
    "    dataset_label = key.split('_')[0]\n",
    "    \n",
    "    baseline = results[0]  # A: ITQ Baseline\n",
    "    best = max(results, key=lambda x: x['recall_at_k'])\n",
    "    best_efficient = max(\n",
    "        [r for r in results if r['reduction'] > 0.5],\n",
    "        key=lambda x: x['recall_at_k'],\n",
    "        default=None\n",
    "    )\n",
    "    \n",
    "    print(f'\\n  [{dataset_label}]')\n",
    "    print(f'    Baseline (A):  R@10={baseline[\"recall_at_k\"]*100:.1f}%')\n",
    "    print(f'    Best overall:  {best[\"name\"]} R@10={best[\"recall_at_k\"]*100:.1f}%')\n",
    "    if best_efficient:\n",
    "        print(f'    Best efficient: {best_efficient[\"name\"]} '\n",
    "              f'R@10={best_efficient[\"recall_at_k\"]*100:.1f}%, '\n",
    "              f'Reduction={best_efficient[\"reduction\"]*100:.1f}%')\n",
    "\n",
    "print('\\n【結論】')\n",
    "print('1. ITQ回転行列の最適化は量子化品質の核心であり、DF-LSHのPCA射影では代替不可')\n",
    "print('2. バンドインデックスはITQハッシュ上でプリフィルタとして利用可能')\n",
    "print('3. Confidence multi-probeにより、バンドフィルタのRecall低下を部分的に回復')\n",
    "print('4. 現行のITQ+Pivotパイプラインが依然として最良のバランス')\n",
    "print('5. バンドプリフィルタの追加は、大規模データ（100K+）で計算量削減の効果が期待')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "別軸での検討によると、この実験に曖昧性があることがわかった。\n",
    "以下を再検証する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "見ました。結論から言うと、\n",
    "\n",
    "* **あなたのNotebook上で「DF-LSHより良い」結果が出るのは、かなり自然**です（＝大発見というより「比較の土俵が違う」ことが主因）。\n",
    "* ただし、それでも **「ITQハッシュに“DF-LSH風の二重フィルタ”を載せると強い」**という方向性自体は、ちゃんと価値のある発見です。\n",
    "\n",
    "以下、`81_dflsh_standalone.ipynb` と `src/dflsh.py` を根拠に、**ITQ-LSH観点での違い**を噛み砕いて整理します。\n",
    "\n",
    "---\n",
    "\n",
    "## 1) あなたの `dflsh.py` は「論文DF-LSHのフル再現」ではなく「概念実装」\n",
    "\n",
    "ファイル冒頭から、これは **“概念実装”**であり、DF-LSH論文の2要素を「対応物として実装」している、という立て付けです。([GitHub][1])\n",
    "\n",
    "そして実装内容を見ると、重要な点が2つあります。\n",
    "\n",
    "### (A) “Data-Aware Hash Bloom Filter (DAHBF)”が、実質「バンド転置インデックス」\n",
    "\n",
    "`build_index()`/`build_band_index()` は、Bloom filter のビット配列を持たず、**「バンドごとに (band_key -> doc_id list)」の辞書**を作っています。([GitHub][1])\n",
    "\n",
    "* これは **LSHの banding（部分コード一致で候補を集める）**に近い\n",
    "* “Bloomフィルタで偽陽性を落とす”という論文の語感とは実装がだいぶ違う\n",
    "\n",
    "> なので Notebook の「DF-LSH」は、実質「PCA符号化 + バンド一致（OR/AND）+ 追加probe」になっています。([GitHub][2])\n",
    "\n",
    "### (B) “幾何学的フィルタ / probe順序”も、かなり素朴（1ビットflip中心）\n",
    "\n",
    "`query_with_multiprobe()` / `confidence_multiprobe()` は、\n",
    "\n",
    "* バンドごとの確信度 = 射影値の絶対値平均\n",
    "* “不確実なバンド”から順に\n",
    "* **そのバンドで最も不確実な1ビットだけ反転**して、同じバンド辞書をもう一度引く\n",
    "\n",
    "…という動きです。([GitHub][1])\n",
    "\n",
    "これ自体は筋が良い（multi-probeの直感）ですが、論文DF-LSHの“幾何”を厳密に再現しているかというと、少なくともこの実装は **簡略版**です。\n",
    "\n",
    "---\n",
    "\n",
    "## 2) ITQ視点で「あなたのITQが勝つ」のは、Notebook内で既に説明されている\n",
    "\n",
    "`81_dflsh_standalone.ipynb` は「DF-LSH独立実装 vs ITQ-LSH」を、まず **バイナリコード品質**で比較しています。([GitHub][2])\n",
    "\n",
    "そこで出ているのが：\n",
    "\n",
    "* **English(E5-base)**: ITQ Spearman = **-0.4717** vs DF(PCA) = **-0.2278**\n",
    "* **Japanese(E5-base)**: ITQ = **-0.5283** vs DF(PCA) = **-0.2771**\n",
    "\n",
    "つまりこの比較では、**PCA符号化（回転なし）で作った2値コードが、ITQ回転ありのコードより「近傍を保てていない」**です。([GitHub][2])\n",
    "\n",
    "> DF-LSHは本来「（同一精度を維持したまま）偽陽性を落として高速化」が売りですが、\n",
    "> そもそも“ハッシュ（2値化）品質”がITQより弱いなら、後段フィルタ以前に負けやすいです。\n",
    "\n",
    "これは「DF-LSHが弱い」のではなく、あなたの比較相手が **“ITQの回転最適化が無いDF-LSH風実装”**だから、という話になります。([GitHub][2])\n",
    "\n",
    "---\n",
    "\n",
    "## 3) じゃあ「DF-LSHより良い」は大発見か？\n",
    "\n",
    "言い方を分けるのが安全です。\n",
    "\n",
    "### ✅ 発見として強い言い方（防衛力高い）\n",
    "\n",
    "* **「PCA符号化だけのDF-LSH風実装より、ITQ回転で得たコードの方が近傍保持が良い」**\n",
    "* **「したがって、バンドインデックスやmulti-probeのような“フィルタ”を載せるなら、ITQハッシュ上に載せた方が強い」**\n",
    "\n",
    "これは Notebook の結果と完全に整合します。([GitHub][2])\n",
    "\n",
    "### ⚠️ まだ危ない言い方\n",
    "\n",
    "* **「（論文の）DF-LSHに勝った」**\n",
    "\n",
    "これは、この `dflsh.py` が **論文DF-LSHの“学習された data-aware hash + Bloom filter + 幾何フィルタ”を同等条件で再現したものではない**可能性が高いので、現時点では突っ込まれます。([GitHub][1])\n",
    "\n",
    "---\n",
    "\n",
    "## 4) ここから「大発見」に育てるための最短ルート\n",
    "\n",
    "あなたが今言いたい価値（＝DF-LSH系の最新研究との比較）に寄せるなら、次の2段が効きます。\n",
    "\n",
    "### (1) 比較の公平性を上げる：ハッシュを揃えて、フィルタだけ比較\n",
    "\n",
    "いまの `81` は **ハッシュ生成自体が違う（ITQ vs PCA符号化）**ので、勝敗がそこで決まります。([GitHub][2])\n",
    "\n",
    "なので修論・論文向けには、\n",
    "\n",
    "* **固定：ITQで作った128bitコード**\n",
    "* 比較：\n",
    "\n",
    "  * (a) そのままHamming top-L\n",
    "  * (b) ITQコードに band index を載せる\n",
    "  * (c) ITQコードに band + confidence multiprobe を載せる\n",
    "  * (d) ITQコードに band + multiprobe + pivot を載せる（あなたの現行）\n",
    "\n",
    "こうすると、あなたの主張は **「DF-LSHの“フィルタ思想”は有効だが、量子化はITQが効く」**になり、説得力が跳ね上がります。\n",
    "\n",
    "### (2) “DF-LSH風”の定義を明記する\n",
    "\n",
    "論文DF-LSHの主張（最大45倍高速化・Recall維持）を引用しつつ、あなたの実装は **“inspired / simplified”**であることを明記。([サイエンスダイレクト][3])\n",
    "\n",
    "その上で「ITQ+二重フィルタは、簡略DF-LSHよりも良いパレートを得た」なら、十分“新規性ある統合”として書けます。\n",
    "\n",
    "---\n",
    "\n",
    "## 5) ついでに：`combined_band_pivot_filter` のPivotは「三角不等式Pivot」ではなく“距離レンジフィルタ”\n",
    "\n",
    "`combined_band_pivot_filter()` は、候補 `x` を\n",
    "\n",
    "> 各pivot i について `d(x,pi)` が `d(q,pi) ± threshold` に入るか\n",
    "\n",
    "で残す方式です。([GitHub][1])\n",
    "\n",
    "これは実装が簡単で効くこともありますが、いわゆる\n",
    "**LB(q,x)=max_i |d(q,pi)-d(x,pi)|** で確実に刈る「安全な下界」フィルタとは別物です（しきい値次第で偽陰性を出し得る）。\n",
    "※この点は、あなたが以前言っていた「Recallを守りやすいPivot」へ寄せるなら、LB型に直すと理論上も守りやすいです。\n",
    "\n",
    "---\n",
    "\n",
    "# まとめ\n",
    "\n",
    "* Notebookの「DF-LSHより良い」は、**（この実装においては）大きな発見というより、ITQ回転が強いので自然に起きる**現象です。([GitHub][2])\n",
    "* でも **「ITQコードにDF-LSH系フィルタ思想を統合すると強い」**は、ちゃんと価値がある発見です（“統合”として主張できる）。\n",
    "\n",
    "もし、次に `84_combined_evaluation.ipynb` 側で「DF-LSHより良い」としている該当表（EN/JAでのPareto）を、**どの設定が“DF-LSH枠”で、どれが“ITQ+フィルタ枠”か**こちらで厳密に整理して、「論文に書ける安全な主張文」に落とします。\n",
    "\n",
    "[1]: https://raw.githubusercontent.com/cmscom/lsh-cascade-poc/refs/heads/main/src/dflsh.py \"raw.githubusercontent.com\"\n",
    "[2]: https://raw.githubusercontent.com/cmscom/lsh-cascade-poc/refs/heads/main/notebooks/81_dflsh_standalone.ipynb \"raw.githubusercontent.com\"\n",
    "[3]: https://www.sciencedirect.com/science/article/abs/pii/S0952197625007420?utm_source=chatgpt.com \"DF-LSH: An efficient Double Filters Locality Sensitive ...\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
